{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "830a28a5-c272-4433-b248-52da479e2830",
    "_uuid": "042c0d49e1208b9c30b727e2d14af3439c35fd3b"
   },
   "source": [
    "# House Price Prediction in King County Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c20ba660-d140-4234-882a-055cbc09808a",
    "_uuid": "a50a9a89f2c75542ab488fae13b0b78fb39da7a3"
   },
   "source": [
    "This is a deep learning version of house price prediction using Keras deep learning package with Tensorflow backend. Dataset from Kaggle. Thanks to ironfrown who shared the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27651695-fa01-43f0-9db6-d7b05a0bab07",
    "_uuid": "ef55b15b777267165fa815006f78fdd27534ccbd"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d691e40-c79d-4089-9cd3-c698a7d36475",
    "_uuid": "53f7e335bf9b238d6208e2e698c418699cd1c0c6"
   },
   "source": [
    "*Load standard Python libraries.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "53a7f6d1-12f4-4874-a5b5-8379c804b941",
    "_uuid": "992bb3c5d9086cebff35a36a96945867a710c65e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c488024e-2fde-455b-84c0-10c091a96869",
    "_uuid": "aa62aa7f38daf18f14ec23704828de8a1bf7b883"
   },
   "source": [
    "*Load Keras libraries.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d5832990-83e4-44b9-a59a-23b96a56d004",
    "_uuid": "e521963b9759a0a2fa076af13d0aecb700758849",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae73d597-0d5f-43e3-9cfc-ca22628998da",
    "_uuid": "a9af9d8e77e32d6709221d9040ba53900194e95d"
   },
   "source": [
    "## Load all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72acf346-259d-49db-a3a7-40cf1a309d84",
    "_uuid": "53d0f01ea8db30613a67bb1ee1b86e0a1d28cbab"
   },
   "source": [
    "*Load data from CSV file and define the label column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ca4e3925-9062-482c-b9d8-f1e391939fc4",
    "_uuid": "ea69f9accd0179ffef96cdb9ad4988cd5d912a2f",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kc_data_org = pd.read_csv(\"./input/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59d23609-ad2c-4cea-b0ff-a31ce8c25da9",
    "_uuid": "3e4875f45acfbf55092aa83d34ca7211f7622c72"
   },
   "source": [
    "*Transform dates into year, month and day and select columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1dd6747c-885f-4d01-866b-5460d1fdbdcd",
    "_uuid": "74278e63c6615bfd23b6b9e92b1b20da0acef4a2",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kc_data_org['sale_yr'] = pd.to_numeric(kc_data_org.date.str.slice(0, 4))\n",
    "kc_data_org['sale_month'] = pd.to_numeric(kc_data_org.date.str.slice(4, 6))\n",
    "kc_data_org['sale_day'] = pd.to_numeric(kc_data_org.date.str.slice(6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sale_yr    sale_month      sale_day      bedrooms     bathrooms  \\\n",
      "count  21613.000000  21613.000000  21613.000000  21613.000000  21613.000000   \n",
      "mean    2014.322954      6.574423     15.688197      3.370842      2.114757   \n",
      "std        0.467616      3.115308      8.635063      0.930062      0.770163   \n",
      "min     2014.000000      1.000000      1.000000      0.000000      0.000000   \n",
      "25%     2014.000000      4.000000      8.000000      3.000000      1.750000   \n",
      "50%     2014.000000      6.000000     16.000000      3.000000      2.250000   \n",
      "75%     2015.000000      9.000000     23.000000      4.000000      2.500000   \n",
      "max     2015.000000     12.000000     31.000000     33.000000      8.000000   \n",
      "\n",
      "        sqft_living      sqft_lot        floors     condition         grade  \\\n",
      "count  21613.000000  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
      "mean    2079.899736  1.510697e+04      1.494309      3.409430      7.656873   \n",
      "std      918.440897  4.142051e+04      0.539989      0.650743      1.175459   \n",
      "min      290.000000  5.200000e+02      1.000000      1.000000      1.000000   \n",
      "25%     1427.000000  5.040000e+03      1.000000      3.000000      7.000000   \n",
      "50%     1910.000000  7.618000e+03      1.500000      3.000000      7.000000   \n",
      "75%     2550.000000  1.068800e+04      2.000000      4.000000      8.000000   \n",
      "max    13540.000000  1.651359e+06      3.500000      5.000000     13.000000   \n",
      "\n",
      "         sqft_above  sqft_basement      yr_built       zipcode           lat  \\\n",
      "count  21613.000000   21613.000000  21613.000000  21613.000000  21613.000000   \n",
      "mean    1788.390691     291.509045   1971.005136  98077.939805     47.560053   \n",
      "std      828.090978     442.575043     29.373411     53.505026      0.138564   \n",
      "min      290.000000       0.000000   1900.000000  98001.000000     47.155900   \n",
      "25%     1190.000000       0.000000   1951.000000  98033.000000     47.471000   \n",
      "50%     1560.000000       0.000000   1975.000000  98065.000000     47.571800   \n",
      "75%     2210.000000     560.000000   1997.000000  98118.000000     47.678000   \n",
      "max     9410.000000    4820.000000   2015.000000  98199.000000     47.777600   \n",
      "\n",
      "               long  sqft_living15     sqft_lot15         price  \n",
      "count  21613.000000   21613.000000   21613.000000  2.161300e+04  \n",
      "mean    -122.213896    1986.552492   12768.455652  5.400881e+05  \n",
      "std        0.140828     685.391304   27304.179631  3.671272e+05  \n",
      "min     -122.519000     399.000000     651.000000  7.500000e+04  \n",
      "25%     -122.328000    1490.000000    5100.000000  3.219500e+05  \n",
      "50%     -122.230000    1840.000000    7620.000000  4.500000e+05  \n",
      "75%     -122.125000    2360.000000   10083.000000  6.450000e+05  \n",
      "max     -121.315000    6210.000000  871200.000000  7.700000e+06  \n"
     ]
    }
   ],
   "source": [
    "kc_data = pd.DataFrame(kc_data_org, columns=[\n",
    "        'sale_yr','sale_month','sale_day',\n",
    "        'bedrooms','bathrooms','sqft_living','sqft_lot','floors',\n",
    "        'condition','grade','sqft_above','sqft_basement','yr_built',\n",
    "        'zipcode','lat','long','sqft_living15','sqft_lot15','price'])\n",
    "label_col = 'price'\n",
    "\n",
    "print(kc_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4eb2feba-12b6-4f64-b9fa-849f4431c89a",
    "_uuid": "ec7cf27228fbbabf311b577e78c2a9be7c358bef"
   },
   "source": [
    "## Split data for training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39f83ce2-bded-4e30-a09d-543fa38a70cb",
    "_uuid": "f01e58fe3636bb8dcf243967fbb07a8d32a374f2"
   },
   "source": [
    "*Function to split a range of data frame / array indeces into three sub-ranges.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "eb613042-355e-41f6-a99c-bda3c24cd5e8",
    "_uuid": "36ef3e310f992ff0f3ab7dd2f58458a32a003fd4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_part=.6, validate_part=.2, test_part=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    total_size = train_part + validate_part + test_part\n",
    "    train_percent = train_part / total_size\n",
    "    validate_percent = validate_part / total_size\n",
    "    test_percent = test_part / total_size\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = perm[:train_end]\n",
    "    validate = perm[train_end:validate_end]\n",
    "    test = perm[validate_end:]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20e5d60a-6427-476b-98c0-0790aa515543",
    "_uuid": "54a54552a95332eea814e0846905dcc99ba74d76"
   },
   "source": [
    "*Split index ranges into three parts, however, ignore the third.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "3bbaa40e-2d07-4668-aa58-23620e695699",
    "_uuid": "04d4b08488a3b1d03378a45f28a902ad1fcd3d27",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size, valid_size, test_size = (70, 30, 0)\n",
    "kc_train, kc_valid, kc_test = train_validate_test_split(kc_data, \n",
    "                              train_part=train_size, \n",
    "                              validate_part=valid_size,\n",
    "                              test_part=test_size,\n",
    "                              seed=2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af43e3fd-49f3-4a64-9e1d-946e04d72e42",
    "_uuid": "5dbe5b8ec4d91cdb4d06bebc3df537c34078940e"
   },
   "source": [
    "*Extract data for training and validation into x and y vectors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "101223b4-b34f-41a0-a36a-c20289f20041",
    "_uuid": "e098d6d1413b910857c0109a36bf65f4c0da1f3e",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  15129\n",
      "Size of training labels:  15129\n",
      "Size of validation set:  6483\n",
      "Size of test set:  1 (not converted)\n"
     ]
    }
   ],
   "source": [
    "kc_y_train = kc_data.loc[kc_train, [label_col]]\n",
    "kc_x_train = kc_data.loc[kc_train, :].drop(label_col, axis=1)\n",
    "kc_y_valid = kc_data.loc[kc_valid, [label_col]]\n",
    "kc_x_valid = kc_data.loc[kc_valid, :].drop(label_col, axis=1)\n",
    "\n",
    "print('Size of training set: ', len(kc_x_train))\n",
    "print('Size of training labels: ', len(kc_y_train))\n",
    "print('Size of validation set: ', len(kc_x_valid))\n",
    "print('Size of test set: ', len(kc_test), '(not converted)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8e0e528f-f3dc-4bd1-b88c-b8649715034e",
    "_uuid": "445d4ebbdc9ea8c8827c08c370452ac5b8dfae97"
   },
   "source": [
    "## Prepare data for training and validation of the Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1a33fd8-c437-4a66-b960-22746771a2c3",
    "_uuid": "4d7d6cc9626ba57a4ffb567c920e3f74ca2c737d"
   },
   "source": [
    "*Function to get statistics about a data frame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b6bdc1ac-7e33-4e5f-8489-40ef4e247401",
    "_uuid": "e57300ecb08215fdb43f73a319c02f23051c1f52",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_stats(df1, df2):\n",
    "    dfs = df1.append(df2)\n",
    "    minimum = np.min(dfs)\n",
    "    maximum = np.max(dfs)\n",
    "    mu = np.mean(dfs)\n",
    "    sigma = np.std(dfs)\n",
    "    return (minimum, maximum, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3e35c68-8445-44fa-84d2-e9491b1d1d4d",
    "_uuid": "b06a85f699fa3fa96906e1155ded54d6ce71e550"
   },
   "source": [
    "*Function to Z-normalise the entire data frame - note stats for Z transform passed in.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "9076dd85-1234-43c2-a177-47dbb0aa8fbc",
    "_uuid": "29a9ad9d369a654666b4471ee4c961c361ebfb77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_score(col, stats):\n",
    "    m, M, mu, s = stats\n",
    "    df = pd.DataFrame()\n",
    "    for c in col.columns:\n",
    "        df[c] = (col[c]-mu[c])/s[c]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84609260-0722-44b7-97f8-655d89764b20",
    "_uuid": "1ecda20bcecb55422141a9b3376d1f0ec8daab08"
   },
   "source": [
    "*Normalise training and validation predictors using the stats from training data only (to ensure the same transformation applies to both training and validation data), and then convert them into numpy arrays to be used by Keras.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "90a93bfc-27a3-4fa4-9790-2c23f4ac00d1",
    "_uuid": "2510528492ed0544ba96c9bfcbf427dd38efe205",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (15129, 18)\n",
      "Training samples:  15129\n",
      "passing values::  18 1\n",
      "Validation samples:  6483\n"
     ]
    }
   ],
   "source": [
    "stats = norm_stats(kc_x_train, kc_x_valid)\n",
    "arr_x_train = np.array(z_score(kc_x_train, stats))\n",
    "arr_y_train = np.array(kc_y_train)\n",
    "arr_x_valid = np.array(z_score(kc_x_valid, stats))\n",
    "arr_y_valid = np.array(kc_y_valid)\n",
    "\n",
    "print('Training shape:', arr_x_train.shape)\n",
    "print('Training samples: ', arr_x_train.shape[0])\n",
    "print('passing values:: ' , arr_x_train.shape[1], arr_y_train.shape[1])\n",
    "print('Validation samples: ', arr_x_valid.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cca5ff68-ac34-4d1c-9ffe-d70b2357a9f8",
    "_uuid": "992d47c8522fe912d22d51b5e694b44f8c01a68a"
   },
   "source": [
    "## Create Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09c266e1-a1cf-4a0c-905f-4c3246bebbee",
    "_uuid": "3800c5d0c46017edf28188524003c301ee5d8398"
   },
   "source": [
    "***Three functions to define alternative Keras models***\n",
    "\n",
    "*simple three layers and Adam optimizer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "8b924410-ecbf-4a68-a41c-28c596834b13",
    "_uuid": "8457d07383484ecd6b2bacdc9f1de4f438017372",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_model_1(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(100, activation=\"tanh\", kernel_initializer='normal', input_shape=(x_size,)))\n",
    "    t_model.add(Dense(50, activation=\"relu\", kernel_initializer='normal'))\n",
    "    t_model.add(Dense(y_size))\n",
    "    print(t_model.summary())\n",
    "    t_model.compile(loss='mean_squared_error',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy'])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fc799e1-acef-4f2c-9684-4292ee723e55",
    "_uuid": "535e03cb14a40704898f8df29707e86b083dae16"
   },
   "source": [
    "*4 layers with Adam optimizer and 10% dropouts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "be0e0159-5771-47ed-a362-52c8b74ab9c1",
    "_uuid": "096dc7ad5771289acd3a653d8d07b76cd6757621",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_model_2(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(100, activation=\"tanh\", input_shape=(x_size,)))\n",
    "    t_model.add(Dropout(0.1))\n",
    "    t_model.add(Dense(50, activation=\"relu\"))\n",
    "    t_model.add(Dense(20, activation=\"relu\"))\n",
    "    t_model.add(Dense(y_size))\n",
    "    print(t_model.summary())\n",
    "    t_model.compile(loss='mean_squared_error',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy'])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c26f0612-565d-49cf-ac84-5e9e8ec76e10",
    "_uuid": "c0a6f3c10ddce3e56046b38d396f292e3e7bc3b8"
   },
   "source": [
    "*Slightly complex, extends the previous model with Nadam optimizer, dropouts and L1/L2 regularisers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "6b3406de-9441-4914-8262-71762be2c72e",
    "_uuid": "97da2a6de65856cdeee64987bb2e2c82cf26c9df",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_model_3(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(80, activation=\"tanh\", kernel_initializer='normal', input_shape=(x_size,)))\n",
    "    t_model.add(Dropout(0.2))\n",
    "    t_model.add(Dense(120, activation=\"relu\", kernel_initializer='normal', \n",
    "        kernel_regularizer=regularizers.l1(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
    "    t_model.add(Dropout(0.1))\n",
    "    t_model.add(Dense(20, activation=\"relu\", kernel_initializer='normal', \n",
    "        kernel_regularizer=regularizers.l1_l2(0.01), bias_regularizer=regularizers.l1_l2(0.01)))\n",
    "    t_model.add(Dropout(0.1))\n",
    "    t_model.add(Dense(10, activation=\"relu\", kernel_initializer='normal'))\n",
    "    t_model.add(Dropout(0.0))\n",
    "    t_model.add(Dense(y_size))\n",
    "    t_model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy'])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04322115-7855-4259-ae2f-7dc505b985d3",
    "_uuid": "2cde05a8d7a29974d8c7337b36458c5789327f18"
   },
   "source": [
    "*Define how many epochs of training should be done and what is the batch size.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "c3bdf585-6a74-4cf2-9b70-3b3b7e55c49a",
    "_uuid": "34a91122b03887c31e16ca44aed196a52ff87e4e",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  500\n",
      "Batch size:  128\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 128\n",
    "\n",
    "print('Epochs: ', epochs)\n",
    "print('Batch size: ', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04eb668a-2327-42de-b508-1a22ce820a5d",
    "_uuid": "28fa5969199f4d3af62b68149fc363fb94c8f820"
   },
   "source": [
    "*Specify Keras callbacks which allow additional functionality while the model is being fitted.*\n",
    "- ***ModelCheckpoint*** *allows to save the models as they are being built or improved.*\n",
    "- ***TensorBoard*** *interacts with TensorFlow interactive reporting system.*\n",
    "- ***EarlyStopping*** *watches one of the model measurements and stops fitting when no improvement.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_callbacks = [\n",
    "    # ModelCheckpoint('/tmp/keras_checkpoints/model.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', save_best_only=True, verbose=2)\n",
    "    # ModelCheckpoint('/tmp/keras_checkpoints/model.{epoch:02d}.hdf5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "    # TensorBoard(log_dir='/tmp/keras_logs/model_3', histogram_freq=1, write_graph=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None),\n",
    "    EarlyStopping(monitor='val_mean_absolute_error', patience=20, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "315c61d3-9fde-41ae-ad75-a446a31ad488",
    "_uuid": "9ad300afc4cf4dd232012d633ca475c3b87af6a8",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./tmp/keras_logs', histogram_freq=1,write_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45b7b912-8175-414b-b556-372bb4d8e885",
    "_uuid": "cdf7f60278e5292290177b61a61329b4fd7b4630"
   },
   "source": [
    "*Fit the model and record the history of training and validation.*<br/>\n",
    "*As we specified EarlyStopping with patience=20, with luck the training will stop in less than 200 epochs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb46a40b-3b81-499f-ad4f-0543545a7246",
    "_uuid": "ec3d528080a6fd0d59481c74f21f56f135744cdc"
   },
   "source": [
    "*Now we create the model - use one of the above functions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a239a746-8dff-46e1-a56d-b3c7eb6e6aef",
    "_uuid": "0f2c81bdc94159272fa7ebee59477cc3abfd3b29"
   },
   "source": [
    "## Fit/Train Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "7a410744-5fb1-46de-9f03-8375ca5cb995",
    "_uuid": "8535f5484e9e0e34523d9adcd3ef9b6fc7cf336f",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 100)               1900      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 7,001\n",
      "Trainable params: 7,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 100)               1900      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 7,001\n",
      "Trainable params: 7,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = basic_model_1(arr_x_train.shape[1], arr_y_train.shape[1])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "52230370-92b1-4f9c-8b7f-4f82208a7841",
    "_uuid": "bb70d9a24530fe50cfaf69daa90714dc53922bec",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15129 samples, validate on 6483 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 418792469608.7081 - acc: 0.0000e+00 - val_loss: 440989889092.6299 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "0s - loss: 418191055108.5856 - acc: 0.0000e+00 - val_loss: 440295656873.6794 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "0s - loss: 417451205590.7802 - acc: 0.0000e+00 - val_loss: 439463515879.1621 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "0s - loss: 416583816484.6005 - acc: 0.0000e+00 - val_loss: 438504024491.4169 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "0s - loss: 415578064792.9841 - acc: 0.0000e+00 - val_loss: 437386103194.9900 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "0s - loss: 414427489201.9597 - acc: 0.0000e+00 - val_loss: 436131048763.7452 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "0s - loss: 413140518531.7480 - acc: 0.0000e+00 - val_loss: 434735877434.4816 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "0s - loss: 411717329845.2085 - acc: 0.0000e+00 - val_loss: 433193079259.7502 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "0s - loss: 410166603497.9518 - acc: 0.0000e+00 - val_loss: 431534969158.6438 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "0s - loss: 408476814564.8416 - acc: 0.0000e+00 - val_loss: 429711172186.7431 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "0s - loss: 406635203831.2518 - acc: 0.0000e+00 - val_loss: 427718228431.4299 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "0s - loss: 404610767581.8362 - acc: 0.0000e+00 - val_loss: 425494409430.1824 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "0s - loss: 402335193770.9374 - acc: 0.0000e+00 - val_loss: 422914909437.5123 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "0s - loss: 399361341705.4589 - acc: 0.0000e+00 - val_loss: 419020888705.5992 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "0s - loss: 395130040377.6673 - acc: 0.0000e+00 - val_loss: 415115880842.5630 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "0s - loss: 391725885488.0560 - acc: 0.0000e+00 - val_loss: 411901064969.2797 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "0s - loss: 388628310591.4543 - acc: 0.0000e+00 - val_loss: 408793547682.0188 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "0s - loss: 385599701347.2087 - acc: 0.0000e+00 - val_loss: 405695484688.0715 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "0s - loss: 382576810226.1754 - acc: 0.0000e+00 - val_loss: 402598831612.7620 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "0s - loss: 379542031774.0266 - acc: 0.0000e+00 - val_loss: 399472040251.5872 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "0s - loss: 376487152561.2828 - acc: 0.0000e+00 - val_loss: 396338281907.1566 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "0s - loss: 373402483002.1918 - acc: 0.0000e+00 - val_loss: 393150006915.9685 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "0s - loss: 370288839994.3949 - acc: 0.0000e+00 - val_loss: 389943382360.3344 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "0s - loss: 367144779603.8104 - acc: 0.0000e+00 - val_loss: 386696532974.4673 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "0s - loss: 363975562221.7928 - acc: 0.0000e+00 - val_loss: 383430007883.0270 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "0s - loss: 360767936980.5127 - acc: 0.0000e+00 - val_loss: 380119631737.1094 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "0s - loss: 357537972507.7337 - acc: 0.0000e+00 - val_loss: 376785451107.5095 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "0s - loss: 354272447227.3467 - acc: 0.0000e+00 - val_loss: 373421753161.5659 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "0s - loss: 350979545374.5765 - acc: 0.0000e+00 - val_loss: 370013193817.0057 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "0s - loss: 347661060738.0559 - acc: 0.0000e+00 - val_loss: 366600751729.8041 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "0s - loss: 344320182093.1773 - acc: 0.0000e+00 - val_loss: 363139360093.5468 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "0s - loss: 340946623941.8251 - acc: 0.0000e+00 - val_loss: 359662955608.2949 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "0s - loss: 337542580531.4234 - acc: 0.0000e+00 - val_loss: 356151804563.6057 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "0s - loss: 334120076677.2540 - acc: 0.0000e+00 - val_loss: 352630439486.1539 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "0s - loss: 330676360315.6597 - acc: 0.0000e+00 - val_loss: 349072840961.4611 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "0s - loss: 327215136864.3829 - acc: 0.0000e+00 - val_loss: 345506487269.9380 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "0s - loss: 323733299526.5104 - acc: 0.0000e+00 - val_loss: 341902485537.1698 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "0s - loss: 320231703710.5850 - acc: 0.0000e+00 - val_loss: 338290967842.1570 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "0s - loss: 316716543586.5826 - acc: 0.0000e+00 - val_loss: 334662298396.3918 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "0s - loss: 313184875135.2131 - acc: 0.0000e+00 - val_loss: 331019002059.4416 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "0s - loss: 309643840381.3011 - acc: 0.0000e+00 - val_loss: 327378559207.2411 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "0s - loss: 306095709080.1042 - acc: 0.0000e+00 - val_loss: 323700927439.8248 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "0s - loss: 302534714879.0862 - acc: 0.0000e+00 - val_loss: 320032493927.4977 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "0s - loss: 298972754540.8030 - acc: 0.0000e+00 - val_loss: 316352732669.7097 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "0s - loss: 295405227667.8570 - acc: 0.0000e+00 - val_loss: 312668576678.7574 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "0s - loss: 291825183652.2874 - acc: 0.0000e+00 - val_loss: 308978125602.7098 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "0s - loss: 288256137256.7461 - acc: 0.0000e+00 - val_loss: 305293616052.9730 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "0s - loss: 284688515054.6727 - acc: 0.0000e+00 - val_loss: 301610276578.1077 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "0s - loss: 281116284596.2102 - acc: 0.0000e+00 - val_loss: 297918305381.2469 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "0s - loss: 277552360663.3046 - acc: 0.0000e+00 - val_loss: 294235420731.0739 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "0s - loss: 273999211729.8899 - acc: 0.0000e+00 - val_loss: 290567129645.5690 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "0s - loss: 270450100605.0642 - acc: 0.0000e+00 - val_loss: 286899659559.4484 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "0s - loss: 266911480599.7742 - acc: 0.0000e+00 - val_loss: 283250536644.4918 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 263393364231.5638 - acc: 0.0000e+00 - val_loss: 279613283544.5516 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "0s - loss: 259886459592.9893 - acc: 0.0000e+00 - val_loss: 275978397729.1698 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "0s - loss: 256393327481.3754 - acc: 0.0000e+00 - val_loss: 272374510429.1519 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "0s - loss: 252913568622.1397 - acc: 0.0000e+00 - val_loss: 268780844907.8414 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "0s - loss: 249451800533.6294 - acc: 0.0000e+00 - val_loss: 265188543504.2690 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "0s - loss: 246016159456.2052 - acc: 0.0000e+00 - val_loss: 261641165461.8170 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "0s - loss: 242603743724.3376 - acc: 0.0000e+00 - val_loss: 258118050018.1866 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "0s - loss: 239213493983.9344 - acc: 0.0000e+00 - val_loss: 254602559968.1728 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 235847574459.7062 - acc: 0.0000e+00 - val_loss: 251110386379.5206 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "0s - loss: 232510654704.2802 - acc: 0.0000e+00 - val_loss: 247659262557.9022 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "0s - loss: 229203432271.6817 - acc: 0.0000e+00 - val_loss: 244229701225.1168 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "0s - loss: 225934034742.4353 - acc: 0.0000e+00 - val_loss: 240852250191.2127 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "0s - loss: 222688864489.2411 - acc: 0.0000e+00 - val_loss: 237492118354.4112 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "0s - loss: 219483614463.3739 - acc: 0.0000e+00 - val_loss: 234156951295.8026 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "0s - loss: 216316685030.2291 - acc: 0.0000e+00 - val_loss: 230876124814.7092 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "0s - loss: 213202716002.3288 - acc: 1.3220e-04 - val_loss: 227633010290.9098 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "0s - loss: 210128960562.4250 - acc: 0.0000e+00 - val_loss: 224449883646.3415 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "0s - loss: 207093263938.0940 - acc: 0.0000e+00 - val_loss: 221299096217.6079 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "0s - loss: 204100577141.7881 - acc: 0.0000e+00 - val_loss: 218182052130.9468 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "0s - loss: 201070810986.6878 - acc: 0.0000e+00 - val_loss: 214941909227.0319 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "0s - loss: 198012607018.0659 - acc: 0.0000e+00 - val_loss: 211791916565.0865 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "0s - loss: 195024154604.7776 - acc: 0.0000e+00 - val_loss: 208696121988.1265 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "0s - loss: 192091873490.6344 - acc: 0.0000e+00 - val_loss: 205630982671.2423 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "0s - loss: 189198511676.4085 - acc: 0.0000e+00 - val_loss: 202616442021.3753 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "0s - loss: 186354822429.6966 - acc: 0.0000e+00 - val_loss: 199646222315.4663 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "0s - loss: 183538726273.1930 - acc: 0.0000e+00 - val_loss: 196705653297.6758 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "0s - loss: 180765654302.5088 - acc: 0.0000e+00 - val_loss: 193826874252.5374 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "0s - loss: 178042627052.4391 - acc: 0.0000e+00 - val_loss: 190965988974.1712 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "0s - loss: 175350355633.5028 - acc: 6.6098e-05 - val_loss: 188134421391.6964 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "0s - loss: 172704713352.0122 - acc: 0.0000e+00 - val_loss: 185364587409.5919 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "0s - loss: 170100738751.7842 - acc: 0.0000e+00 - val_loss: 182644461502.9240 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "0s - loss: 167535652433.7968 - acc: 0.0000e+00 - val_loss: 179965262234.3582 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "0s - loss: 165013998218.1781 - acc: 0.0000e+00 - val_loss: 177305655371.5009 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "0s - loss: 162542355106.1384 - acc: 0.0000e+00 - val_loss: 174710582117.6813 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "0s - loss: 160109805657.8851 - acc: 0.0000e+00 - val_loss: 172149788569.0156 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "0s - loss: 157716707987.6539 - acc: 0.0000e+00 - val_loss: 169647881284.7089 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "0s - loss: 155370237111.8990 - acc: 0.0000e+00 - val_loss: 167173641880.8181 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "0s - loss: 153065205292.4349 - acc: 0.0000e+00 - val_loss: 164744783265.7819 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "0s - loss: 150811499790.2645 - acc: 0.0000e+00 - val_loss: 162388217990.5747 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "0s - loss: 148606033113.1998 - acc: 0.0000e+00 - val_loss: 160060937921.2538 - val_acc: 1.5425e-04\n",
      "Epoch 94/500\n",
      "0s - loss: 146444862988.6232 - acc: 0.0000e+00 - val_loss: 157768625902.4279 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "0s - loss: 144316044280.0809 - acc: 0.0000e+00 - val_loss: 155525357091.6181 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "0s - loss: 142237196983.2560 - acc: 0.0000e+00 - val_loss: 153341756157.7492 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "0s - loss: 140206072138.8422 - acc: 0.0000e+00 - val_loss: 151196673047.5348 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "0s - loss: 138218809937.8645 - acc: 0.0000e+00 - val_loss: 149087997030.1947 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "0s - loss: 136278803536.6123 - acc: 0.0000e+00 - val_loss: 147027398585.8695 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "0s - loss: 134384883850.2119 - acc: 0.0000e+00 - val_loss: 145024937154.4384 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "0s - loss: 132529290772.3392 - acc: 0.0000e+00 - val_loss: 143063599340.6115 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "0s - loss: 130710288179.9987 - acc: 0.0000e+00 - val_loss: 141119100674.9616 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "0s - loss: 128932028896.2898 - acc: 0.0000e+00 - val_loss: 139235508476.7225 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "0s - loss: 127179662747.1838 - acc: 0.0000e+00 - val_loss: 137362901094.6685 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "0s - loss: 125464401081.3881 - acc: 0.0000e+00 - val_loss: 135539606965.9997 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "0s - loss: 123766113885.8447 - acc: 0.0000e+00 - val_loss: 133734916228.6793 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "0s - loss: 122100734184.4288 - acc: 6.6098e-05 - val_loss: 131956412011.0122 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "0s - loss: 120458962785.0089 - acc: 0.0000e+00 - val_loss: 130228729522.0904 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "0s - loss: 118852300874.5884 - acc: 0.0000e+00 - val_loss: 128520127468.5720 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "0s - loss: 117276068807.4834 - acc: 0.0000e+00 - val_loss: 126848842344.3270 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "0s - loss: 115721414192.9021 - acc: 0.0000e+00 - val_loss: 125195700954.6839 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "0s - loss: 114190045500.4931 - acc: 6.6098e-05 - val_loss: 123577438345.1020 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "0s - loss: 112693550124.4688 - acc: 0.0000e+00 - val_loss: 121994007314.5988 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "0s - loss: 111215078380.3038 - acc: 0.0000e+00 - val_loss: 120440343738.8567 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "0s - loss: 109775491415.8377 - acc: 0.0000e+00 - val_loss: 118898794186.4149 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "0s - loss: 108358479918.8377 - acc: 0.0000e+00 - val_loss: 117403506499.4058 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "0s - loss: 106960218193.8983 - acc: 0.0000e+00 - val_loss: 115931289628.7472 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "0s - loss: 105595676514.5657 - acc: 0.0000e+00 - val_loss: 114469686467.7020 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "0s - loss: 104247644720.0222 - acc: 0.0000e+00 - val_loss: 113055120129.2241 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "0s - loss: 102933602138.8496 - acc: 0.0000e+00 - val_loss: 111672578110.5488 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "0s - loss: 101645812384.7847 - acc: 0.0000e+00 - val_loss: 110306820485.1927 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "0s - loss: 100387615761.5303 - acc: 0.0000e+00 - val_loss: 108960849980.6534 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "0s - loss: 99147740349.1784 - acc: 0.0000e+00 - val_loss: 107656692688.7725 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "0s - loss: 97926648515.4392 - acc: 0.0000e+00 - val_loss: 106358388343.9642 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "0s - loss: 96737119130.8792 - acc: 0.0000e+00 - val_loss: 105089340879.9037 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "0s - loss: 95575782403.1812 - acc: 0.0000e+00 - val_loss: 103863532263.9519 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "0s - loss: 94432807930.3822 - acc: 0.0000e+00 - val_loss: 102647135285.5456 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "0s - loss: 93311710422.3571 - acc: 0.0000e+00 - val_loss: 101461356246.4193 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "0s - loss: 92213769812.3688 - acc: 0.0000e+00 - val_loss: 100315437169.4092 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "0s - loss: 91125461209.4029 - acc: 0.0000e+00 - val_loss: 99156060234.8690 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "0s - loss: 90078472855.8504 - acc: 0.0000e+00 - val_loss: 98056404044.2906 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "0s - loss: 89060841032.4563 - acc: 0.0000e+00 - val_loss: 96980824975.6964 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "0s - loss: 88053437570.5636 - acc: 0.0000e+00 - val_loss: 95890724600.8527 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "0s - loss: 87059774040.6329 - acc: 0.0000e+00 - val_loss: 94835845063.4533 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "0s - loss: 86075062498.4726 - acc: 6.6098e-05 - val_loss: 93789459192.0629 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "0s - loss: 85097592713.6874 - acc: 0.0000e+00 - val_loss: 92734567889.1674 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "0s - loss: 84137031327.6341 - acc: 0.0000e+00 - val_loss: 91717928221.1026 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "0s - loss: 83186702841.8745 - acc: 0.0000e+00 - val_loss: 90705285048.6059 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "0s - loss: 82252578195.4678 - acc: 0.0000e+00 - val_loss: 89718040701.4135 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "0s - loss: 81328262300.2837 - acc: 0.0000e+00 - val_loss: 88737005979.9377 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "0s - loss: 80410619157.0330 - acc: 0.0000e+00 - val_loss: 87760273751.7026 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "0s - loss: 79511818792.0354 - acc: 0.0000e+00 - val_loss: 86796245238.0885 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "0s - loss: 78626997616.7456 - acc: 0.0000e+00 - val_loss: 85848643243.7723 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "0s - loss: 77753660294.3708 - acc: 0.0000e+00 - val_loss: 84935051352.7688 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "0s - loss: 76876171934.4834 - acc: 0.0000e+00 - val_loss: 84009197966.0379 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "0s - loss: 76009708445.9250 - acc: 6.6098e-05 - val_loss: 83110991073.0810 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "0s - loss: 75160615170.9612 - acc: 0.0000e+00 - val_loss: 82212362521.4697 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "0s - loss: 74310767008.0571 - acc: 0.0000e+00 - val_loss: 81311500346.4421 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "0s - loss: 73465243288.8656 - acc: 6.6098e-05 - val_loss: 80439942417.4142 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "0s - loss: 72620448365.2091 - acc: 0.0000e+00 - val_loss: 79583926013.9071 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "0s - loss: 71788467186.3954 - acc: 0.0000e+00 - val_loss: 78736773718.3205 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "0s - loss: 70974991872.1692 - acc: 0.0000e+00 - val_loss: 77925206512.9156 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "0s - loss: 70180670871.5965 - acc: 0.0000e+00 - val_loss: 77124270875.7600 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "0s - loss: 69404556465.0629 - acc: 0.0000e+00 - val_loss: 76339785082.9258 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "0s - loss: 68650013785.5467 - acc: 0.0000e+00 - val_loss: 75578922276.0524 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "0s - loss: 67907996500.5550 - acc: 0.0000e+00 - val_loss: 74829712810.9431 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "0s - loss: 67183355888.6356 - acc: 0.0000e+00 - val_loss: 74104638820.1808 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "0s - loss: 66477138703.5167 - acc: 0.0000e+00 - val_loss: 73390785687.1597 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "0s - loss: 65768293303.9159 - acc: 0.0000e+00 - val_loss: 72671248415.5903 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "0s - loss: 65077681842.7211 - acc: 6.6098e-05 - val_loss: 71986940248.0185 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "0s - loss: 64402914411.5846 - acc: 0.0000e+00 - val_loss: 71301269661.0039 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "0s - loss: 63735952794.1009 - acc: 6.6098e-05 - val_loss: 70653436006.3526 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "0s - loss: 63066673373.7347 - acc: 0.0000e+00 - val_loss: 69978406774.2662 - val_acc: 1.5425e-04\n",
      "Epoch 164/500\n",
      "0s - loss: 62425486149.6982 - acc: 0.0000e+00 - val_loss: 69339646165.8664 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "0s - loss: 61802938725.1038 - acc: 0.0000e+00 - val_loss: 68730392666.3483 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "0s - loss: 61188921291.4768 - acc: 6.6098e-05 - val_loss: 68110674945.1057 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "0s - loss: 60583141835.1722 - acc: 0.0000e+00 - val_loss: 67515174479.2127 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "0s - loss: 59976992419.4244 - acc: 0.0000e+00 - val_loss: 66896962607.5434 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "0s - loss: 59375840078.1926 - acc: 0.0000e+00 - val_loss: 66295915084.8434 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "0s - loss: 58764664956.8781 - acc: 0.0000e+00 - val_loss: 65683280378.0768 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "0s - loss: 58173988883.4932 - acc: 6.6098e-05 - val_loss: 65089231276.0487 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "0s - loss: 57598837748.5613 - acc: 6.6098e-05 - val_loss: 64519770118.9499 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "0s - loss: 57029060250.3547 - acc: 0.0000e+00 - val_loss: 63945670926.4131 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "0s - loss: 56469900097.7386 - acc: 0.0000e+00 - val_loss: 63398398805.2544 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "0s - loss: 55901899052.9256 - acc: 0.0000e+00 - val_loss: 62834340179.2800 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "0s - loss: 55357645675.5677 - acc: 0.0000e+00 - val_loss: 62307325889.7671 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "0s - loss: 54816748655.6119 - acc: 0.0000e+00 - val_loss: 61788678731.8957 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "0s - loss: 54290241741.5581 - acc: 0.0000e+00 - val_loss: 61264245632.5331 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "0s - loss: 53768886734.5564 - acc: 0.0000e+00 - val_loss: 60765940124.2536 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "0s - loss: 53253754953.0993 - acc: 0.0000e+00 - val_loss: 60258311428.7780 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "0s - loss: 52741727761.7672 - acc: 0.0000e+00 - val_loss: 59769168161.3673 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "0s - loss: 52234890588.9140 - acc: 0.0000e+00 - val_loss: 59291976344.6602 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "0s - loss: 51738193542.8615 - acc: 0.0000e+00 - val_loss: 58817779625.7584 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "0s - loss: 51246372879.5675 - acc: 0.0000e+00 - val_loss: 58339728979.6354 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "0s - loss: 50763562086.0007 - acc: 0.0000e+00 - val_loss: 57872245930.1138 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "0s - loss: 50289975050.7111 - acc: 0.0000e+00 - val_loss: 57416821545.0279 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "0s - loss: 49828490249.0020 - acc: 6.6098e-05 - val_loss: 56980806006.9770 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "0s - loss: 49371788811.4725 - acc: 0.0000e+00 - val_loss: 56532182672.6047 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "0s - loss: 48927535176.8286 - acc: 0.0000e+00 - val_loss: 56094336844.8829 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "0s - loss: 48482021641.6281 - acc: 0.0000e+00 - val_loss: 55674700057.7856 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "0s - loss: 48055400544.5182 - acc: 6.6098e-05 - val_loss: 55255000258.1225 - val_acc: 1.5425e-04\n",
      "Epoch 192/500\n",
      "0s - loss: 47630097619.1082 - acc: 6.6098e-05 - val_loss: 54850397817.8596 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "0s - loss: 47220275648.0719 - acc: 0.0000e+00 - val_loss: 54435896521.3882 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "0s - loss: 46817067692.1557 - acc: 0.0000e+00 - val_loss: 54039024379.8538 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "0s - loss: 46412555007.2724 - acc: 0.0000e+00 - val_loss: 53649811269.3012 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "0s - loss: 46011750701.6025 - acc: 0.0000e+00 - val_loss: 53266664305.0538 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "0s - loss: 45627200541.7812 - acc: 0.0000e+00 - val_loss: 52904432449.3525 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "0s - loss: 45239792457.3532 - acc: 0.0000e+00 - val_loss: 52531764223.2102 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "0s - loss: 44864300713.2453 - acc: 0.0000e+00 - val_loss: 52180499475.4280 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "0s - loss: 44495770678.8245 - acc: 0.0000e+00 - val_loss: 51844114810.1360 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "0s - loss: 44130570354.3193 - acc: 0.0000e+00 - val_loss: 51498402104.7441 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "0s - loss: 43774166787.9426 - acc: 0.0000e+00 - val_loss: 51167236063.7779 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "0s - loss: 43425951008.9455 - acc: 0.0000e+00 - val_loss: 50841140444.3424 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "0s - loss: 43073433149.7622 - acc: 0.0000e+00 - val_loss: 50508005556.6966 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "0s - loss: 42716711834.5916 - acc: 0.0000e+00 - val_loss: 50176158360.3443 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "0s - loss: 42389613274.3166 - acc: 0.0000e+00 - val_loss: 49876857077.1408 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "0s - loss: 42060847405.6025 - acc: 0.0000e+00 - val_loss: 49557444442.1509 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "0s - loss: 41741746519.9730 - acc: 0.0000e+00 - val_loss: 49260560869.2272 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "0s - loss: 41429796034.8639 - acc: 0.0000e+00 - val_loss: 48976791976.2579 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "0s - loss: 41120372065.2458 - acc: 0.0000e+00 - val_loss: 48683315061.0026 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "0s - loss: 40819014410.7788 - acc: 0.0000e+00 - val_loss: 48397235067.4786 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "0s - loss: 40520101739.2970 - acc: 0.0000e+00 - val_loss: 48114229623.2929 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "0s - loss: 40226307089.9364 - acc: 0.0000e+00 - val_loss: 47836142761.1661 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "0s - loss: 39937332562.4906 - acc: 0.0000e+00 - val_loss: 47562105247.7285 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "0s - loss: 39665091572.9674 - acc: 0.0000e+00 - val_loss: 47296635691.8710 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "0s - loss: 39399424290.4345 - acc: 0.0000e+00 - val_loss: 47047493633.5795 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "0s - loss: 39136505831.4305 - acc: 0.0000e+00 - val_loss: 46786607259.1084 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "0s - loss: 38884287080.2004 - acc: 0.0000e+00 - val_loss: 46546809747.4873 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "0s - loss: 38636095491.9257 - acc: 0.0000e+00 - val_loss: 46307376313.5931 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "0s - loss: 38394901827.2954 - acc: 6.6098e-05 - val_loss: 46064096749.5986 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "0s - loss: 38152610872.0428 - acc: 0.0000e+00 - val_loss: 45839003970.8530 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "0s - loss: 37910859265.8275 - acc: 0.0000e+00 - val_loss: 45610737926.8314 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "0s - loss: 37682024942.0974 - acc: 0.0000e+00 - val_loss: 45376657220.6694 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "0s - loss: 37447840040.9322 - acc: 0.0000e+00 - val_loss: 45145864283.2960 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "0s - loss: 37223820516.0294 - acc: 0.0000e+00 - val_loss: 44928823041.3821 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "0s - loss: 36998644947.9204 - acc: 0.0000e+00 - val_loss: 44714285307.7748 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "0s - loss: 36775680154.2532 - acc: 0.0000e+00 - val_loss: 44493005299.1269 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "0s - loss: 36563243052.4011 - acc: 0.0000e+00 - val_loss: 44287802398.8006 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "0s - loss: 36348242165.9658 - acc: 0.0000e+00 - val_loss: 44080428289.3031 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "0s - loss: 36133227043.5682 - acc: 0.0000e+00 - val_loss: 43880481704.3369 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "0s - loss: 35924168857.1702 - acc: 0.0000e+00 - val_loss: 43684552750.1219 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "0s - loss: 35721430825.9814 - acc: 0.0000e+00 - val_loss: 43466896293.1778 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "0s - loss: 35526011822.9816 - acc: 0.0000e+00 - val_loss: 43262092902.2736 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "0s - loss: 35322253813.4074 - acc: 6.6098e-05 - val_loss: 43089336007.5718 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "0s - loss: 35120806800.7942 - acc: 0.0000e+00 - val_loss: 42895621181.7591 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "0s - loss: 34927419034.6254 - acc: 0.0000e+00 - val_loss: 42706598992.7132 - val_acc: 1.5425e-04\n",
      "Epoch 237/500\n",
      "0s - loss: 34730547509.8600 - acc: 0.0000e+00 - val_loss: 42531356796.4658 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "0s - loss: 34542065288.8582 - acc: 0.0000e+00 - val_loss: 42348941701.8245 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "0s - loss: 34357160119.4252 - acc: 0.0000e+00 - val_loss: 42168894843.8735 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "0s - loss: 34173081921.9079 - acc: 0.0000e+00 - val_loss: 41991240425.2155 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "0s - loss: 33992845928.9449 - acc: 0.0000e+00 - val_loss: 41823600994.4433 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "0s - loss: 33809183572.4196 - acc: 0.0000e+00 - val_loss: 41631960069.5283 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "0s - loss: 33647018821.1229 - acc: 0.0000e+00 - val_loss: 41472143755.5107 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "0s - loss: 33466038960.3522 - acc: 0.0000e+00 - val_loss: 41317999770.9505 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "0s - loss: 33288088124.4762 - acc: 0.0000e+00 - val_loss: 41152587968.3850 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "0s - loss: 33116820200.4627 - acc: 0.0000e+00 - val_loss: 40989315886.3983 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "0s - loss: 32949657613.5708 - acc: 0.0000e+00 - val_loss: 40835679712.9625 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "0s - loss: 32779173318.8404 - acc: 0.0000e+00 - val_loss: 40640166179.5786 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "0s - loss: 32620109068.5047 - acc: 0.0000e+00 - val_loss: 40481783018.8740 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "0s - loss: 32459719570.5540 - acc: 0.0000e+00 - val_loss: 40339399216.4122 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "0s - loss: 32303096668.1356 - acc: 0.0000e+00 - val_loss: 40180661857.5351 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "0s - loss: 32132839969.8761 - acc: 0.0000e+00 - val_loss: 40006326674.1447 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "0s - loss: 31977763331.6211 - acc: 0.0000e+00 - val_loss: 39861662380.8780 - val_acc: 1.5425e-04\n",
      "Epoch 254/500\n",
      "0s - loss: 31821068309.7606 - acc: 0.0000e+00 - val_loss: 39707804188.8262 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "0s - loss: 31664455135.2068 - acc: 6.6098e-05 - val_loss: 39571004295.7989 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "0s - loss: 31513118821.6961 - acc: 0.0000e+00 - val_loss: 39417164472.2505 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "0s - loss: 31362348270.9943 - acc: 0.0000e+00 - val_loss: 39299917056.6713 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "0s - loss: 31206391658.2817 - acc: 0.0000e+00 - val_loss: 39124485724.1647 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "0s - loss: 31056162450.4017 - acc: 0.0000e+00 - val_loss: 38991929309.2507 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "0s - loss: 30912250849.5419 - acc: 0.0000e+00 - val_loss: 38839095044.5411 - val_acc: 1.5425e-04\n",
      "Epoch 261/500\n",
      "0s - loss: 30767101735.3755 - acc: 0.0000e+00 - val_loss: 38714065280.7700 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "0s - loss: 30629543779.2764 - acc: 0.0000e+00 - val_loss: 38578677172.1043 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "0s - loss: 30487026007.6346 - acc: 0.0000e+00 - val_loss: 38464369397.5357 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "0s - loss: 30351739885.2514 - acc: 0.0000e+00 - val_loss: 38323840144.2098 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "0s - loss: 30212344048.8217 - acc: 0.0000e+00 - val_loss: 38202656154.8320 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "0s - loss: 30085272205.6807 - acc: 0.0000e+00 - val_loss: 38072965383.7791 - val_acc: 1.5425e-04\n",
      "Epoch 267/500\n",
      "0s - loss: 29951824006.1847 - acc: 0.0000e+00 - val_loss: 37946990578.7321 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "0s - loss: 29823028871.9445 - acc: 0.0000e+00 - val_loss: 37843215267.9142 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "0s - loss: 29689999253.3291 - acc: 0.0000e+00 - val_loss: 37717993906.9986 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "0s - loss: 29560863336.2681 - acc: 0.0000e+00 - val_loss: 37612941580.5177 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "0s - loss: 29440665416.9809 - acc: 0.0000e+00 - val_loss: 37542819745.5450 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "0s - loss: 29309512390.1466 - acc: 0.0000e+00 - val_loss: 37375775045.3802 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "0s - loss: 29187644393.7318 - acc: 6.6098e-05 - val_loss: 37304125888.8983 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "0s - loss: 29079651403.4345 - acc: 0.0000e+00 - val_loss: 37191087682.8925 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "0s - loss: 28958446024.3294 - acc: 0.0000e+00 - val_loss: 37066818510.8771 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "0s - loss: 28850866378.7492 - acc: 0.0000e+00 - val_loss: 36974315592.3418 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "0s - loss: 28738465180.8082 - acc: 0.0000e+00 - val_loss: 36898311897.5783 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "0s - loss: 28615000716.7501 - acc: 0.0000e+00 - val_loss: 36771608373.5061 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "0s - loss: 28510766189.1752 - acc: 0.0000e+00 - val_loss: 36672454909.9861 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "0s - loss: 28395991681.9205 - acc: 0.0000e+00 - val_loss: 36600829582.7092 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "0s - loss: 28300007834.0332 - acc: 0.0000e+00 - val_loss: 36516957643.1652 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "0s - loss: 28192323773.3815 - acc: 0.0000e+00 - val_loss: 36389382945.4462 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "0s - loss: 28085079908.7316 - acc: 0.0000e+00 - val_loss: 36314249570.1274 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "0s - loss: 28006095754.4319 - acc: 0.0000e+00 - val_loss: 36250107514.8073 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "0s - loss: 27892708335.9588 - acc: 0.0000e+00 - val_loss: 36140068676.9853 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "0s - loss: 27793576152.3199 - acc: 0.0000e+00 - val_loss: 36041400265.0329 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "0s - loss: 27702634423.8482 - acc: 0.0000e+00 - val_loss: 35952149801.7387 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "0s - loss: 27604789789.6120 - acc: 0.0000e+00 - val_loss: 35854118492.4806 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "0s - loss: 27505231418.4456 - acc: 0.0000e+00 - val_loss: 35733049356.0043 - val_acc: 1.5425e-04\n",
      "Epoch 290/500\n",
      "0s - loss: 27416429970.6556 - acc: 0.0000e+00 - val_loss: 35697929275.2318 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "0s - loss: 27325551776.2094 - acc: 0.0000e+00 - val_loss: 35591945179.8291 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "0s - loss: 27231593280.7911 - acc: 6.6098e-05 - val_loss: 35502090221.9935 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "0s - loss: 27142591605.0266 - acc: 0.0000e+00 - val_loss: 35451609976.9514 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "0s - loss: 27061393263.3581 - acc: 0.0000e+00 - val_loss: 35341095547.5971 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "0s - loss: 26971367368.6340 - acc: 0.0000e+00 - val_loss: 35301481061.1680 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "0s - loss: 26882434221.5771 - acc: 0.0000e+00 - val_loss: 35178589268.5041 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "0s - loss: 26797521337.9803 - acc: 0.0000e+00 - val_loss: 35119621120.7898 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "0s - loss: 26715987613.4005 - acc: 0.0000e+00 - val_loss: 35046549748.1931 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "0s - loss: 26635187870.3481 - acc: 6.6098e-05 - val_loss: 34991058488.4677 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "0s - loss: 26544293402.6000 - acc: 0.0000e+00 - val_loss: 34850043137.9349 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "0s - loss: 26473294324.5275 - acc: 0.0000e+00 - val_loss: 34792011274.6617 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "0s - loss: 26382724989.3688 - acc: 0.0000e+00 - val_loss: 34699430547.9216 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "0s - loss: 26304670549.1641 - acc: 0.0000e+00 - val_loss: 34645897001.8177 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "0s - loss: 26226082869.6739 - acc: 0.0000e+00 - val_loss: 34542873256.7712 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "0s - loss: 26148674992.3014 - acc: 0.0000e+00 - val_loss: 34516866166.3057 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "0s - loss: 26077029754.2383 - acc: 0.0000e+00 - val_loss: 34429048185.3463 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "0s - loss: 25989127459.1114 - acc: 0.0000e+00 - val_loss: 34327564143.9482 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "0s - loss: 25920606904.0682 - acc: 0.0000e+00 - val_loss: 34261417282.0632 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "0s - loss: 25841416556.1430 - acc: 0.0000e+00 - val_loss: 34202855429.3703 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "0s - loss: 25780418041.6715 - acc: 0.0000e+00 - val_loss: 34107059256.0728 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "0s - loss: 25693953421.2408 - acc: 0.0000e+00 - val_loss: 34013135551.2004 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "0s - loss: 25631248664.9925 - acc: 0.0000e+00 - val_loss: 33928988971.7921 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "0s - loss: 25563881604.3910 - acc: 0.0000e+00 - val_loss: 33879241613.1692 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "0s - loss: 25478170753.0406 - acc: 0.0000e+00 - val_loss: 33848347244.1178 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "0s - loss: 25412436078.6643 - acc: 0.0000e+00 - val_loss: 33770393134.3588 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "0s - loss: 25351069532.5417 - acc: 0.0000e+00 - val_loss: 33713078376.2480 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "0s - loss: 25284656907.6587 - acc: 0.0000e+00 - val_loss: 33607927426.0731 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "0s - loss: 25223747191.5648 - acc: 0.0000e+00 - val_loss: 33614913045.0865 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "0s - loss: 25154315177.0253 - acc: 0.0000e+00 - val_loss: 33593497786.0669 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "0s - loss: 25089180623.4702 - acc: 0.0000e+00 - val_loss: 33481193728.8292 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "0s - loss: 25016342279.2592 - acc: 0.0000e+00 - val_loss: 33347456455.6903 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "0s - loss: 24970861095.4940 - acc: 0.0000e+00 - val_loss: 33299162884.5411 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "0s - loss: 24898053764.8310 - acc: 0.0000e+00 - val_loss: 33277858422.8586 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "0s - loss: 24839056856.4722 - acc: 0.0000e+00 - val_loss: 33203343843.0159 - val_acc: 1.5425e-04\n",
      "Epoch 325/500\n",
      "0s - loss: 24769508141.8732 - acc: 0.0000e+00 - val_loss: 33165383213.4111 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "0s - loss: 24717940153.1004 - acc: 0.0000e+00 - val_loss: 33090418025.2352 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "0s - loss: 24651619028.0896 - acc: 0.0000e+00 - val_loss: 33075825285.3901 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "0s - loss: 24600155022.3576 - acc: 0.0000e+00 - val_loss: 33026543718.9844 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "0s - loss: 24536257031.9529 - acc: 0.0000e+00 - val_loss: 32910814915.1492 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "0s - loss: 24472474968.3115 - acc: 0.0000e+00 - val_loss: 32849671960.4430 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "0s - loss: 24414916435.4043 - acc: 0.0000e+00 - val_loss: 32853781832.0654 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "0s - loss: 24355061493.8981 - acc: 1.3220e-04 - val_loss: 32770681273.9485 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "0s - loss: 24296394145.9523 - acc: 0.0000e+00 - val_loss: 32725068070.1058 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "0s - loss: 24246059649.5144 - acc: 0.0000e+00 - val_loss: 32659406581.6937 - val_acc: 1.5425e-04\n",
      "Epoch 335/500\n",
      "0s - loss: 24184229259.6164 - acc: 0.0000e+00 - val_loss: 32627752525.9491 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "0s - loss: 24137193229.6892 - acc: 0.0000e+00 - val_loss: 32585752856.2061 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "0s - loss: 24082564825.9782 - acc: 0.0000e+00 - val_loss: 32508596939.8365 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "0s - loss: 24018364920.8593 - acc: 0.0000e+00 - val_loss: 32447448750.9314 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "0s - loss: 23980664541.0578 - acc: 0.0000e+00 - val_loss: 32442826204.5399 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "0s - loss: 23918665799.0350 - acc: 0.0000e+00 - val_loss: 32370092587.9895 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "0s - loss: 23886704072.9386 - acc: 0.0000e+00 - val_loss: 32262632270.6204 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "0s - loss: 23814964464.2126 - acc: 0.0000e+00 - val_loss: 32258996888.9761 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "0s - loss: 23777340790.0250 - acc: 0.0000e+00 - val_loss: 32232385759.5015 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "0s - loss: 23719033768.8223 - acc: 0.0000e+00 - val_loss: 32163308518.2539 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "0s - loss: 23670529993.5816 - acc: 6.6098e-05 - val_loss: 32119884978.3273 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "0s - loss: 23611509775.5675 - acc: 0.0000e+00 - val_loss: 32067953163.7674 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "0s - loss: 23571981039.6373 - acc: 0.0000e+00 - val_loss: 32033100466.2483 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "0s - loss: 23537469126.2820 - acc: 0.0000e+00 - val_loss: 32033314416.3825 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "0s - loss: 23472488072.2829 - acc: 0.0000e+00 - val_loss: 31878589644.2314 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "0s - loss: 23432676605.1065 - acc: 0.0000e+00 - val_loss: 31846787148.4486 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "0s - loss: 23378927855.0619 - acc: 0.0000e+00 - val_loss: 31857046767.6125 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "0s - loss: 23335557721.2421 - acc: 0.0000e+00 - val_loss: 31801626409.5018 - val_acc: 1.5425e-04\n",
      "Epoch 353/500\n",
      "0s - loss: 23286763179.9527 - acc: 0.0000e+00 - val_loss: 31772884594.5939 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "0s - loss: 23238791463.9170 - acc: 0.0000e+00 - val_loss: 31703782203.3503 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "0s - loss: 23185687079.0202 - acc: 0.0000e+00 - val_loss: 31668579890.4655 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "0s - loss: 23143149254.7558 - acc: 0.0000e+00 - val_loss: 31586299802.2792 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "0s - loss: 23103804373.5956 - acc: 6.6098e-05 - val_loss: 31538494593.0464 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "0s - loss: 23055217477.7320 - acc: 0.0000e+00 - val_loss: 31531399972.2894 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "0s - loss: 23011684180.7580 - acc: 6.6098e-05 - val_loss: 31472600572.4461 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "0s - loss: 22957241139.8633 - acc: 0.0000e+00 - val_loss: 31386554238.1638 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "0s - loss: 22921890144.5690 - acc: 0.0000e+00 - val_loss: 31413539400.7367 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "0s - loss: 22876947430.3814 - acc: 0.0000e+00 - val_loss: 31353615744.2962 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "0s - loss: 22834413371.8162 - acc: 0.0000e+00 - val_loss: 31308228386.2360 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "0s - loss: 22789060565.6295 - acc: 0.0000e+00 - val_loss: 31271147841.5894 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "0s - loss: 22752283918.0276 - acc: 0.0000e+00 - val_loss: 31242778518.1725 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "0s - loss: 22701575519.2153 - acc: 6.6098e-05 - val_loss: 31205540150.2169 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "0s - loss: 22655692460.5618 - acc: 0.0000e+00 - val_loss: 31186006804.8101 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "0s - loss: 22622029674.7555 - acc: 0.0000e+00 - val_loss: 31096601569.1994 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "0s - loss: 22588908904.8265 - acc: 0.0000e+00 - val_loss: 31039347317.2790 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "0s - loss: 22550677266.6640 - acc: 0.0000e+00 - val_loss: 31032989746.8604 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "0s - loss: 22503416555.1701 - acc: 0.0000e+00 - val_loss: 31007951711.3633 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "0s - loss: 22461006897.2067 - acc: 0.0000e+00 - val_loss: 30965521539.5737 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "0s - loss: 22420043984.6546 - acc: 0.0000e+00 - val_loss: 30980917344.9823 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "0s - loss: 22383871247.7536 - acc: 0.0000e+00 - val_loss: 31009388802.0929 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "0s - loss: 22353811976.7990 - acc: 0.0000e+00 - val_loss: 30952193464.2110 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "0s - loss: 22299461392.6673 - acc: 0.0000e+00 - val_loss: 30868115256.3492 - val_acc: 1.5425e-04\n",
      "Epoch 377/500\n",
      "0s - loss: 22263483311.8953 - acc: 0.0000e+00 - val_loss: 30867276837.4345 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "0s - loss: 22227374266.5387 - acc: 0.0000e+00 - val_loss: 30817081536.3850 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "0s - loss: 22195768713.0444 - acc: 0.0000e+00 - val_loss: 30853329512.3270 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "0s - loss: 22150580863.3485 - acc: 6.6098e-05 - val_loss: 30799190697.0871 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "0s - loss: 22122652013.1245 - acc: 0.0000e+00 - val_loss: 30751950746.2792 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "0s - loss: 22083009326.7870 - acc: 0.0000e+00 - val_loss: 30700679485.7985 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "0s - loss: 22038669849.7201 - acc: 0.0000e+00 - val_loss: 30660735036.0216 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "0s - loss: 22001624954.9321 - acc: 0.0000e+00 - val_loss: 30628387682.8382 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "0s - loss: 21966847442.5498 - acc: 0.0000e+00 - val_loss: 30584301598.6426 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "0s - loss: 21936081684.2546 - acc: 0.0000e+00 - val_loss: 30608310487.4459 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "0s - loss: 21898163362.7137 - acc: 6.6098e-05 - val_loss: 30563090258.2533 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "0s - loss: 21869350645.0520 - acc: 0.0000e+00 - val_loss: 30510178066.4408 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "0s - loss: 21839854512.6060 - acc: 0.0000e+00 - val_loss: 30472552123.2516 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "0s - loss: 21779222316.9595 - acc: 0.0000e+00 - val_loss: 30517045753.1291 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "0s - loss: 21755117569.9967 - acc: 0.0000e+00 - val_loss: 30449129179.1578 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "0s - loss: 21722254726.3370 - acc: 0.0000e+00 - val_loss: 30443981820.6830 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "0s - loss: 21696847939.5830 - acc: 0.0000e+00 - val_loss: 30457895093.6443 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "0s - loss: 21649094729.5055 - acc: 0.0000e+00 - val_loss: 30390060486.7426 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "0s - loss: 21611052503.6261 - acc: 0.0000e+00 - val_loss: 30358691671.9395 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "0s - loss: 21576484540.7384 - acc: 0.0000e+00 - val_loss: 30364580013.1149 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "0s - loss: 21546932167.1111 - acc: 0.0000e+00 - val_loss: 30286300874.7308 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "0s - loss: 21499354208.0952 - acc: 0.0000e+00 - val_loss: 30346679236.1364 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "0s - loss: 21464083548.9309 - acc: 0.0000e+00 - val_loss: 30271622666.0299 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "0s - loss: 21435995231.5029 - acc: 0.0000e+00 - val_loss: 30245255014.1552 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "0s - loss: 21412079751.7753 - acc: 0.0000e+00 - val_loss: 30207447346.4260 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "0s - loss: 21366305041.0734 - acc: 6.6098e-05 - val_loss: 30151607558.6735 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "0s - loss: 21342612016.2929 - acc: 0.0000e+00 - val_loss: 30175987230.2477 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "0s - loss: 21310055968.7255 - acc: 0.0000e+00 - val_loss: 30190017937.0390 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "0s - loss: 21265898614.6511 - acc: 0.0000e+00 - val_loss: 30125183954.6679 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "0s - loss: 21219400015.8509 - acc: 0.0000e+00 - val_loss: 30121388969.2846 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "0s - loss: 21203292735.0482 - acc: 0.0000e+00 - val_loss: 30072638860.9323 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "0s - loss: 21164510759.5616 - acc: 0.0000e+00 - val_loss: 30071240994.3150 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "0s - loss: 21138863436.8051 - acc: 0.0000e+00 - val_loss: 30044013644.9224 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "0s - loss: 21102383940.6152 - acc: 0.0000e+00 - val_loss: 30025153409.1649 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "0s - loss: 21064180102.2693 - acc: 0.0000e+00 - val_loss: 29988569668.3141 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "0s - loss: 21060975721.1142 - acc: 0.0000e+00 - val_loss: 29959973029.2173 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "0s - loss: 21017967376.1935 - acc: 0.0000e+00 - val_loss: 30021775906.1965 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "0s - loss: 20984062350.2899 - acc: 0.0000e+00 - val_loss: 29983682476.2857 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "0s - loss: 20950775652.1055 - acc: 0.0000e+00 - val_loss: 29967498581.6492 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "0s - loss: 20916299789.7400 - acc: 0.0000e+00 - val_loss: 29908713083.4392 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "0s - loss: 20871874602.3705 - acc: 0.0000e+00 - val_loss: 29876394599.6952 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "0s - loss: 20839367907.5556 - acc: 0.0000e+00 - val_loss: 29972231823.3410 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "0s - loss: 20823556686.6156 - acc: 0.0000e+00 - val_loss: 29835246166.0046 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "0s - loss: 20793085187.6380 - acc: 0.0000e+00 - val_loss: 29843803208.8157 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "0s - loss: 20757579091.0659 - acc: 0.0000e+00 - val_loss: 29781284686.4624 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "0s - loss: 20756185995.3456 - acc: 6.6098e-05 - val_loss: 29825063243.3824 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "0s - loss: 20722149314.4070 - acc: 0.0000e+00 - val_loss: 29798704060.8706 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "0s - loss: 20680579477.0245 - acc: 0.0000e+00 - val_loss: 29757390338.7641 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "0s - loss: 20664899949.5813 - acc: 0.0000e+00 - val_loss: 29719438898.7814 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "0s - loss: 20628842199.6431 - acc: 0.0000e+00 - val_loss: 29719696018.9739 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "0s - loss: 20602740639.3464 - acc: 0.0000e+00 - val_loss: 29745132479.3978 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "0s - loss: 20571922193.8857 - acc: 0.0000e+00 - val_loss: 29674686403.9784 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "0s - loss: 20552457657.7434 - acc: 0.0000e+00 - val_loss: 29678336176.5899 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "0s - loss: 20527458966.1582 - acc: 0.0000e+00 - val_loss: 29665972508.3128 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "0s - loss: 20479012297.8862 - acc: 0.0000e+00 - val_loss: 29640716596.6374 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "0s - loss: 20463530997.3735 - acc: 0.0000e+00 - val_loss: 29656263969.5252 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "0s - loss: 20440483303.0582 - acc: 0.0000e+00 - val_loss: 29593327048.3221 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "0s - loss: 20426822525.5718 - acc: 0.0000e+00 - val_loss: 29637443757.7467 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "0s - loss: 20390813874.4842 - acc: 0.0000e+00 - val_loss: 29584851568.2246 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "0s - loss: 20366158597.4994 - acc: 0.0000e+00 - val_loss: 29568668215.0461 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "0s - loss: 20348908761.0644 - acc: 0.0000e+00 - val_loss: 29558500012.8780 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "0s - loss: 20305348869.3978 - acc: 0.0000e+00 - val_loss: 29538871015.1621 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "0s - loss: 20292596693.9679 - acc: 0.0000e+00 - val_loss: 29575191099.1529 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "0s - loss: 20266137218.1913 - acc: 0.0000e+00 - val_loss: 29508289146.3335 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "0s - loss: 20237531543.3935 - acc: 0.0000e+00 - val_loss: 29553831985.2809 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "0s - loss: 20203355036.4360 - acc: 0.0000e+00 - val_loss: 29514719587.7069 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "0s - loss: 20180047265.5462 - acc: 0.0000e+00 - val_loss: 29464076702.1490 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "0s - loss: 20161583063.9138 - acc: 0.0000e+00 - val_loss: 29493689956.0623 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "0s - loss: 20150712658.3891 - acc: 0.0000e+00 - val_loss: 29418690478.1811 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "0s - loss: 20109046434.6122 - acc: 0.0000e+00 - val_loss: 29445461496.9712 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "0s - loss: 20077550217.6366 - acc: 0.0000e+00 - val_loss: 29434286053.4641 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "0s - loss: 20058263438.0192 - acc: 0.0000e+00 - val_loss: 29420411641.0106 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "0s - loss: 20047799252.3434 - acc: 0.0000e+00 - val_loss: 29388696401.7794 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "0s - loss: 20029628732.4931 - acc: 0.0000e+00 - val_loss: 29406952787.1220 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "0s - loss: 19992133407.8287 - acc: 0.0000e+00 - val_loss: 29414223788.2857 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "0s - loss: 19979277891.7184 - acc: 0.0000e+00 - val_loss: 29342364267.1701 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "0s - loss: 19939646760.6615 - acc: 0.0000e+00 - val_loss: 29386393088.5528 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "0s - loss: 19924872558.3766 - acc: 0.0000e+00 - val_loss: 29367566398.8647 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "0s - loss: 19893465272.6435 - acc: 0.0000e+00 - val_loss: 29393295877.1334 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "0s - loss: 19871541083.7295 - acc: 0.0000e+00 - val_loss: 29358610178.3298 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "0s - loss: 19845457725.5084 - acc: 0.0000e+00 - val_loss: 29358018016.0148 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "0s - loss: 19830746090.6794 - acc: 0.0000e+00 - val_loss: 29352525189.3506 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "0s - loss: 19795333239.2602 - acc: 6.6098e-05 - val_loss: 29304764380.9348 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "0s - loss: 19788156218.8010 - acc: 0.0000e+00 - val_loss: 29358426332.8163 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "0s - loss: 19758284337.2405 - acc: 0.0000e+00 - val_loss: 29289909326.5019 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "0s - loss: 19732158304.8736 - acc: 0.0000e+00 - val_loss: 29285129424.3381 - val_acc: 1.5425e-04\n",
      "Epoch 463/500\n",
      "0s - loss: 19718062321.3124 - acc: 0.0000e+00 - val_loss: 29261254114.5420 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "0s - loss: 19681943663.0027 - acc: 0.0000e+00 - val_loss: 29270759151.0597 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "0s - loss: 19673781048.7366 - acc: 6.6098e-05 - val_loss: 29278578308.2844 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "0s - loss: 19655907603.3409 - acc: 0.0000e+00 - val_loss: 29239909205.2544 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "0s - loss: 19622626212.4228 - acc: 0.0000e+00 - val_loss: 29234532249.0156 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "0s - loss: 19590430021.9012 - acc: 0.0000e+00 - val_loss: 29224174726.4168 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "0s - loss: 19572442868.6798 - acc: 0.0000e+00 - val_loss: 29244948190.0009 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "0s - loss: 19553950058.7555 - acc: 0.0000e+00 - val_loss: 29167130007.3571 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "0s - loss: 19526261870.7997 - acc: 0.0000e+00 - val_loss: 29241511245.1199 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "0s - loss: 19508412319.9556 - acc: 0.0000e+00 - val_loss: 29198604261.4641 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "0s - loss: 19485932523.0178 - acc: 0.0000e+00 - val_loss: 29209050521.8843 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "0s - loss: 19466674531.3440 - acc: 0.0000e+00 - val_loss: 29116934536.3517 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "0s - loss: 19437167605.0013 - acc: 0.0000e+00 - val_loss: 29207412772.9607 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "0s - loss: 19418641513.0465 - acc: 0.0000e+00 - val_loss: 29128339975.9766 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "0s - loss: 19394920294.7621 - acc: 0.0000e+00 - val_loss: 29100852506.8913 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "0s - loss: 19386713418.0300 - acc: 0.0000e+00 - val_loss: 29093736349.4382 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "0s - loss: 19353303588.4481 - acc: 6.6098e-05 - val_loss: 29100582140.2486 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "0s - loss: 19343300727.5310 - acc: 0.0000e+00 - val_loss: 29080766977.3426 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "0s - loss: 19316387229.0621 - acc: 0.0000e+00 - val_loss: 29095841458.0904 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "0s - loss: 19295915745.5589 - acc: 0.0000e+00 - val_loss: 29069917603.9932 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "0s - loss: 19283364629.8790 - acc: 0.0000e+00 - val_loss: 29079946396.5300 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "0s - loss: 19256659600.5404 - acc: 0.0000e+00 - val_loss: 29015967702.9326 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "0s - loss: 19223701702.8573 - acc: 0.0000e+00 - val_loss: 29038466980.7040 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "0s - loss: 19207302252.9045 - acc: 0.0000e+00 - val_loss: 29062115886.8326 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "0s - loss: 19189145818.0120 - acc: 0.0000e+00 - val_loss: 29014265899.5946 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "0s - loss: 19168807203.5852 - acc: 0.0000e+00 - val_loss: 29010495089.0143 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "0s - loss: 19155982799.6394 - acc: 0.0000e+00 - val_loss: 29080564746.5828 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "0s - loss: 19109763054.2328 - acc: 0.0000e+00 - val_loss: 28964336565.2889 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "0s - loss: 19107418369.4721 - acc: 0.0000e+00 - val_loss: 28976970408.7713 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "0s - loss: 19075556805.4528 - acc: 0.0000e+00 - val_loss: 28998765604.8027 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "0s - loss: 19070354275.7163 - acc: 0.0000e+00 - val_loss: 28970508304.7429 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "0s - loss: 19043895736.2205 - acc: 0.0000e+00 - val_loss: 28961960401.9571 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "0s - loss: 19011710477.3000 - acc: 6.6098e-05 - val_loss: 28947782927.8346 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "0s - loss: 19020205251.1346 - acc: 0.0000e+00 - val_loss: 28926882263.0116 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "0s - loss: 18981246258.6788 - acc: 0.0000e+00 - val_loss: 28935362963.0924 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "0s - loss: 18958106945.9079 - acc: 0.0000e+00 - val_loss: 28927364640.7749 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "0s - loss: 18948933496.7662 - acc: 0.0000e+00 - val_loss: 28934392578.1718 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "0s - loss: 18934311959.9265 - acc: 0.0000e+00 - val_loss: 28903201145.5042 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(arr_x_train, arr_y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2, # Change it to 2, if wished to observe execution\n",
    "    validation_data=(arr_x_valid, arr_y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "7a410744-5fb1-46de-9f03-8375ca5cb995",
    "_uuid": "8535f5484e9e0e34523d9adcd3ef9b6fc7cf336f",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 100)               1900      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 7,991\n",
      "Trainable params: 7,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 100)               1900      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 7,991\n",
      "Trainable params: 7,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = basic_model_2(arr_x_train.shape[1], arr_y_train.shape[1])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "52230370-92b1-4f9c-8b7f-4f82208a7841",
    "_uuid": "bb70d9a24530fe50cfaf69daa90714dc53922bec",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15129 samples, validate on 6483 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 419690701164.4138 - acc: 0.0000e+00 - val_loss: 442050334558.8894 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "0s - loss: 418705858471.7393 - acc: 0.0000e+00 - val_loss: 439675556550.7820 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "0s - loss: 414168655733.7881 - acc: 0.0000e+00 - val_loss: 432165279334.2736 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "0s - loss: 403562892352.2327 - acc: 0.0000e+00 - val_loss: 417449459780.2351 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "0s - loss: 385396643223.3935 - acc: 0.0000e+00 - val_loss: 394480396167.0090 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "0s - loss: 359268518109.8701 - acc: 0.0000e+00 - val_loss: 363515452966.1453 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "0s - loss: 326067061713.9068 - acc: 0.0000e+00 - val_loss: 326153642005.4814 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "0s - loss: 288004060766.1154 - acc: 0.0000e+00 - val_loss: 285152804616.3320 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "0s - loss: 248137199276.2234 - acc: 0.0000e+00 - val_loss: 244117935030.8684 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "0s - loss: 209896290219.6650 - acc: 0.0000e+00 - val_loss: 206349355062.6512 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "0s - loss: 177063442956.2847 - acc: 6.6098e-05 - val_loss: 175408623228.7028 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "0s - loss: 151785702848.0042 - acc: 0.0000e+00 - val_loss: 152803612264.8009 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "0s - loss: 134353757020.1356 - acc: 0.0000e+00 - val_loss: 137911041771.2689 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "0s - loss: 123447830673.5218 - acc: 0.0000e+00 - val_loss: 129010229121.6387 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "0s - loss: 117311756499.8527 - acc: 0.0000e+00 - val_loss: 124044972416.7700 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "0s - loss: 114045398728.9217 - acc: 0.0000e+00 - val_loss: 121435301956.5510 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "0s - loss: 112456814255.4723 - acc: 0.0000e+00 - val_loss: 120027242613.5160 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "0s - loss: 111234161528.6985 - acc: 0.0000e+00 - val_loss: 119102868558.1860 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "0s - loss: 110704910840.1147 - acc: 0.0000e+00 - val_loss: 118323247049.3488 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "0s - loss: 109941671434.1865 - acc: 0.0000e+00 - val_loss: 117833486854.7129 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "0s - loss: 109445773611.0305 - acc: 0.0000e+00 - val_loss: 117286368139.9056 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "0s - loss: 108876917566.4898 - acc: 0.0000e+00 - val_loss: 116821796002.5322 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "0s - loss: 108370749289.8756 - acc: 0.0000e+00 - val_loss: 116298326210.5963 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "0s - loss: 107847991542.9133 - acc: 0.0000e+00 - val_loss: 115747577257.0477 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "0s - loss: 106944271557.4359 - acc: 0.0000e+00 - val_loss: 115025393313.6634 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "0s - loss: 106089644095.6235 - acc: 0.0000e+00 - val_loss: 114274333774.5019 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "0s - loss: 105367049037.7865 - acc: 0.0000e+00 - val_loss: 113369453163.8019 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "0s - loss: 104720858886.9207 - acc: 0.0000e+00 - val_loss: 112390066610.0509 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "0s - loss: 103125144107.9611 - acc: 0.0000e+00 - val_loss: 111254374765.4999 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "0s - loss: 101967495080.0100 - acc: 0.0000e+00 - val_loss: 109981522305.0859 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "0s - loss: 100775901194.6942 - acc: 0.0000e+00 - val_loss: 108607079445.0076 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "0s - loss: 99170889512.7630 - acc: 0.0000e+00 - val_loss: 107171926534.7129 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "0s - loss: 97674175639.2750 - acc: 0.0000e+00 - val_loss: 105573195626.8937 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "0s - loss: 96087343498.1950 - acc: 0.0000e+00 - val_loss: 104081285058.0830 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "0s - loss: 94700425572.0209 - acc: 0.0000e+00 - val_loss: 102656235883.6045 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "0s - loss: 93114124167.6568 - acc: 0.0000e+00 - val_loss: 101183777911.8852 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "0s - loss: 91967425929.9919 - acc: 0.0000e+00 - val_loss: 99778049702.7179 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "0s - loss: 90104152126.8113 - acc: 0.0000e+00 - val_loss: 98275473338.1854 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "0s - loss: 88681626303.7843 - acc: 0.0000e+00 - val_loss: 96868257618.2533 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "0s - loss: 87250169658.6318 - acc: 0.0000e+00 - val_loss: 95465629705.1612 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "0s - loss: 86071197479.2740 - acc: 0.0000e+00 - val_loss: 94117633296.1505 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "0s - loss: 84771378474.2859 - acc: 0.0000e+00 - val_loss: 92774509359.3460 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "0s - loss: 83326832173.2471 - acc: 0.0000e+00 - val_loss: 91416298302.1934 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "0s - loss: 81882153238.3190 - acc: 0.0000e+00 - val_loss: 90075188471.5101 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "0s - loss: 80420248450.4451 - acc: 0.0000e+00 - val_loss: 88662634769.5721 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "0s - loss: 78764461081.1110 - acc: 0.0000e+00 - val_loss: 87246227305.9460 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "0s - loss: 77617705315.4794 - acc: 0.0000e+00 - val_loss: 85806808864.3406 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "0s - loss: 76046579351.5119 - acc: 0.0000e+00 - val_loss: 84274306443.9846 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "0s - loss: 74435252562.5583 - acc: 0.0000e+00 - val_loss: 82720808086.8438 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "0s - loss: 73092947490.9591 - acc: 0.0000e+00 - val_loss: 81288733757.4432 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "0s - loss: 71560093323.1933 - acc: 0.0000e+00 - val_loss: 79907683176.8403 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "0s - loss: 70299708672.9984 - acc: 0.0000e+00 - val_loss: 78669250127.8445 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "0s - loss: 68861757552.2210 - acc: 0.0000e+00 - val_loss: 77508632944.9749 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 67857013246.6125 - acc: 0.0000e+00 - val_loss: 76505235315.7390 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "0s - loss: 66932083184.1280 - acc: 0.0000e+00 - val_loss: 75472312911.0548 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "0s - loss: 65700136613.3196 - acc: 0.0000e+00 - val_loss: 74494600386.1225 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "0s - loss: 64942727193.4494 - acc: 6.6098e-05 - val_loss: 73543148963.0455 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "0s - loss: 63885730395.2050 - acc: 0.0000e+00 - val_loss: 72637680993.6535 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "0s - loss: 62933866395.9622 - acc: 0.0000e+00 - val_loss: 71712209308.8854 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "0s - loss: 62385724615.8726 - acc: 0.0000e+00 - val_loss: 70924556766.5932 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "0s - loss: 61503042880.2157 - acc: 0.0000e+00 - val_loss: 70125335251.4182 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 60774974524.0362 - acc: 0.0000e+00 - val_loss: 69334094699.0517 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "0s - loss: 59897409928.8413 - acc: 0.0000e+00 - val_loss: 68605369559.2880 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "0s - loss: 59187351073.6054 - acc: 0.0000e+00 - val_loss: 67914919951.1634 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "0s - loss: 58654344078.0869 - acc: 0.0000e+00 - val_loss: 67197798710.5328 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "0s - loss: 58115436079.1423 - acc: 0.0000e+00 - val_loss: 66561883551.5706 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "0s - loss: 57307959597.1964 - acc: 0.0000e+00 - val_loss: 65886428563.5663 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "0s - loss: 56842223975.5405 - acc: 0.0000e+00 - val_loss: 65306047175.4138 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "0s - loss: 56604403904.7657 - acc: 0.0000e+00 - val_loss: 64742687736.5763 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "0s - loss: 55938776731.1669 - acc: 0.0000e+00 - val_loss: 64140049302.9622 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "0s - loss: 54959736218.1009 - acc: 0.0000e+00 - val_loss: 63512886855.6310 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "0s - loss: 54478728508.0193 - acc: 0.0000e+00 - val_loss: 62978194697.2007 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "0s - loss: 54146606764.3588 - acc: 0.0000e+00 - val_loss: 62366010451.8723 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "0s - loss: 53490603100.2541 - acc: 6.6098e-05 - val_loss: 61857968358.6093 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "0s - loss: 53281141313.4848 - acc: 0.0000e+00 - val_loss: 61277946664.0802 - val_acc: 1.5425e-04\n",
      "Epoch 76/500\n",
      "0s - loss: 52142099838.6209 - acc: 0.0000e+00 - val_loss: 60710065969.0835 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "0s - loss: 52183604176.5531 - acc: 0.0000e+00 - val_loss: 60152975648.1037 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "0s - loss: 51174891380.5698 - acc: 0.0000e+00 - val_loss: 59692569780.2227 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "0s - loss: 51279812653.0779 - acc: 0.0000e+00 - val_loss: 59188416398.9067 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "0s - loss: 50611073004.5068 - acc: 0.0000e+00 - val_loss: 58675313977.2180 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "0s - loss: 50209803832.8889 - acc: 0.0000e+00 - val_loss: 58178912654.6698 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "0s - loss: 50014969589.3228 - acc: 0.0000e+00 - val_loss: 57558519478.1971 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "0s - loss: 49081340963.9405 - acc: 0.0000e+00 - val_loss: 56999872106.6963 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "0s - loss: 48684934635.0516 - acc: 0.0000e+00 - val_loss: 56446853774.5513 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "0s - loss: 47943802177.4341 - acc: 0.0000e+00 - val_loss: 55831410808.3591 - val_acc: 1.5425e-04\n",
      "Epoch 86/500\n",
      "0s - loss: 47913716826.7650 - acc: 0.0000e+00 - val_loss: 55273717895.8383 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "0s - loss: 47074211001.6588 - acc: 0.0000e+00 - val_loss: 54755335796.4893 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "0s - loss: 46388632769.3748 - acc: 0.0000e+00 - val_loss: 54157374702.3489 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "0s - loss: 46099302913.1845 - acc: 0.0000e+00 - val_loss: 53569570407.5373 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "0s - loss: 45514716040.4013 - acc: 0.0000e+00 - val_loss: 52990126381.6875 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "0s - loss: 44625531820.2742 - acc: 0.0000e+00 - val_loss: 52436735074.7197 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "0s - loss: 44493091093.9129 - acc: 0.0000e+00 - val_loss: 51800147976.5294 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "0s - loss: 44083676628.1742 - acc: 0.0000e+00 - val_loss: 51136551626.2570 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "0s - loss: 43177558309.4803 - acc: 0.0000e+00 - val_loss: 50471317888.1382 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "0s - loss: 42949757290.1125 - acc: 0.0000e+00 - val_loss: 49830647130.3878 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "0s - loss: 42528888045.9113 - acc: 0.0000e+00 - val_loss: 49172632619.1208 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "0s - loss: 42156358567.2655 - acc: 0.0000e+00 - val_loss: 48431887636.8891 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "0s - loss: 40974304306.8311 - acc: 0.0000e+00 - val_loss: 47781697165.4456 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "0s - loss: 40552599531.5593 - acc: 0.0000e+00 - val_loss: 47079427443.3441 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "0s - loss: 40693259419.4715 - acc: 0.0000e+00 - val_loss: 46436725528.2850 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "0s - loss: 40104348137.3595 - acc: 0.0000e+00 - val_loss: 45890542259.5120 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "0s - loss: 39276902968.0090 - acc: 0.0000e+00 - val_loss: 45376126648.7244 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "0s - loss: 38714216914.3467 - acc: 0.0000e+00 - val_loss: 44796488940.1376 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "0s - loss: 38347969870.5649 - acc: 0.0000e+00 - val_loss: 44266816328.9341 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "0s - loss: 37613292898.1934 - acc: 0.0000e+00 - val_loss: 43834014388.7756 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "0s - loss: 37599745940.6523 - acc: 0.0000e+00 - val_loss: 43439034904.4035 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "0s - loss: 37336221149.9208 - acc: 0.0000e+00 - val_loss: 43130698785.9596 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "0s - loss: 37160468647.7901 - acc: 0.0000e+00 - val_loss: 42806462335.4274 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "0s - loss: 37033515456.3427 - acc: 0.0000e+00 - val_loss: 42449370990.0527 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "0s - loss: 36506279129.0644 - acc: 6.6098e-05 - val_loss: 42173205771.0961 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "0s - loss: 37061990551.4781 - acc: 0.0000e+00 - val_loss: 41920206602.5433 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "0s - loss: 36609703962.4647 - acc: 0.0000e+00 - val_loss: 41704234575.2127 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "0s - loss: 36289171707.3128 - acc: 0.0000e+00 - val_loss: 41492277322.2372 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "0s - loss: 35475374884.6343 - acc: 0.0000e+00 - val_loss: 41173543080.3764 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "0s - loss: 35679051269.3809 - acc: 0.0000e+00 - val_loss: 41001288733.2210 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "0s - loss: 35347537792.6176 - acc: 0.0000e+00 - val_loss: 40863887651.2627 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "0s - loss: 35318099709.8510 - acc: 0.0000e+00 - val_loss: 40594989956.9557 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "0s - loss: 35601524919.4252 - acc: 0.0000e+00 - val_loss: 40500160629.2001 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "0s - loss: 35556794222.6135 - acc: 0.0000e+00 - val_loss: 40234223976.4455 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "0s - loss: 34873616629.1535 - acc: 0.0000e+00 - val_loss: 40067431662.6648 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "0s - loss: 34718587968.0973 - acc: 0.0000e+00 - val_loss: 39867232805.0396 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "0s - loss: 34688384030.6611 - acc: 0.0000e+00 - val_loss: 39727314881.7671 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "0s - loss: 34086761450.8147 - acc: 0.0000e+00 - val_loss: 39600150082.8925 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "0s - loss: 34177609567.3168 - acc: 0.0000e+00 - val_loss: 39415359139.5588 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "0s - loss: 34254069165.4587 - acc: 0.0000e+00 - val_loss: 39359590255.9482 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "0s - loss: 34495376809.9391 - acc: 0.0000e+00 - val_loss: 39158432097.1797 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "0s - loss: 33776700822.7166 - acc: 0.0000e+00 - val_loss: 39001646613.4024 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "0s - loss: 34202724210.8100 - acc: 0.0000e+00 - val_loss: 38910654088.0753 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "0s - loss: 33360469819.9855 - acc: 0.0000e+00 - val_loss: 38749523559.8532 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "0s - loss: 33713103843.8432 - acc: 0.0000e+00 - val_loss: 38576746785.9991 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "0s - loss: 33538081511.0413 - acc: 0.0000e+00 - val_loss: 38428453935.8593 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "0s - loss: 33676134452.9293 - acc: 0.0000e+00 - val_loss: 38433776592.7725 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "0s - loss: 33975649174.7505 - acc: 0.0000e+00 - val_loss: 38216045471.4916 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "0s - loss: 33094753649.0163 - acc: 0.0000e+00 - val_loss: 38099213927.8532 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "0s - loss: 33022463503.3982 - acc: 0.0000e+00 - val_loss: 37970254858.2669 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "0s - loss: 33333924470.0081 - acc: 0.0000e+00 - val_loss: 37838186728.8206 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "0s - loss: 33180269436.3535 - acc: 0.0000e+00 - val_loss: 37718987414.7648 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "0s - loss: 33286381255.0265 - acc: 0.0000e+00 - val_loss: 37595183154.8604 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "0s - loss: 33406497283.9257 - acc: 0.0000e+00 - val_loss: 37598402796.6114 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "0s - loss: 32931697802.8211 - acc: 0.0000e+00 - val_loss: 37388457116.8459 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "0s - loss: 32484264848.1851 - acc: 0.0000e+00 - val_loss: 37294107351.2090 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "0s - loss: 32541801342.1133 - acc: 0.0000e+00 - val_loss: 37151318033.0588 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "0s - loss: 32541002008.9587 - acc: 0.0000e+00 - val_loss: 37066200559.1782 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "0s - loss: 32598753689.2887 - acc: 0.0000e+00 - val_loss: 37092466106.4223 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "0s - loss: 32710217031.6610 - acc: 0.0000e+00 - val_loss: 36880064716.7052 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "0s - loss: 32354905774.5247 - acc: 0.0000e+00 - val_loss: 36812603730.3323 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "0s - loss: 31928008172.2699 - acc: 6.6098e-05 - val_loss: 36712904632.2900 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "0s - loss: 32527244455.9254 - acc: 0.0000e+00 - val_loss: 36560973793.6733 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "0s - loss: 32159943872.2919 - acc: 0.0000e+00 - val_loss: 36511785686.8931 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "0s - loss: 31569065482.5926 - acc: 0.0000e+00 - val_loss: 36414533803.2195 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "0s - loss: 31678737990.4258 - acc: 0.0000e+00 - val_loss: 36281804128.0740 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "0s - loss: 32191070756.1097 - acc: 0.0000e+00 - val_loss: 36204290269.7640 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "0s - loss: 32184544270.9583 - acc: 0.0000e+00 - val_loss: 36283181885.8775 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "0s - loss: 31400691747.0606 - acc: 0.0000e+00 - val_loss: 36006208662.5278 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "0s - loss: 31884145424.7350 - acc: 0.0000e+00 - val_loss: 35990750144.0296 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "0s - loss: 32118028595.9648 - acc: 0.0000e+00 - val_loss: 35917181784.7293 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "0s - loss: 30595524370.5625 - acc: 0.0000e+00 - val_loss: 35797915873.2389 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "0s - loss: 31033314409.3849 - acc: 0.0000e+00 - val_loss: 35760016243.5811 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "0s - loss: 31179651996.7744 - acc: 0.0000e+00 - val_loss: 35633200063.0819 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "0s - loss: 30616464315.8755 - acc: 0.0000e+00 - val_loss: 35437098920.4948 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "0s - loss: 30700975988.4344 - acc: 0.0000e+00 - val_loss: 35442627787.9155 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "0s - loss: 31157201209.5150 - acc: 0.0000e+00 - val_loss: 35358345421.6529 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "0s - loss: 31111148816.8365 - acc: 0.0000e+00 - val_loss: 35336366473.2994 - val_acc: 1.5425e-04\n",
      "Epoch 164/500\n",
      "0s - loss: 31077964802.7751 - acc: 0.0000e+00 - val_loss: 35213880557.0853 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "0s - loss: 30338693675.5550 - acc: 0.0000e+00 - val_loss: 35120806285.4061 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "0s - loss: 30592182184.0777 - acc: 0.0000e+00 - val_loss: 35184113648.2048 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "0s - loss: 31183069556.6036 - acc: 0.0000e+00 - val_loss: 34915433979.4984 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "0s - loss: 30206728679.5997 - acc: 0.0000e+00 - val_loss: 34865605027.2035 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "0s - loss: 30275984266.5673 - acc: 0.0000e+00 - val_loss: 34763470044.9742 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "0s - loss: 30185826972.7236 - acc: 6.6098e-05 - val_loss: 34617911535.4546 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "0s - loss: 30612918904.7154 - acc: 0.0000e+00 - val_loss: 34551362103.0461 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "0s - loss: 30173051387.7697 - acc: 0.0000e+00 - val_loss: 34506430243.4996 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "0s - loss: 29792492994.0348 - acc: 0.0000e+00 - val_loss: 34380867266.5174 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "0s - loss: 29759450402.5699 - acc: 0.0000e+00 - val_loss: 34321630235.9574 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "0s - loss: 29961480990.1366 - acc: 6.6098e-05 - val_loss: 34295001383.6853 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "0s - loss: 29994641525.7712 - acc: 0.0000e+00 - val_loss: 34195371233.3969 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "0s - loss: 29521883882.3579 - acc: 0.0000e+00 - val_loss: 34128347562.4692 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "0s - loss: 29368699656.6805 - acc: 0.0000e+00 - val_loss: 34016795679.4324 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "0s - loss: 29065492402.9073 - acc: 0.0000e+00 - val_loss: 34042103529.6893 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "0s - loss: 29632565219.8432 - acc: 0.0000e+00 - val_loss: 33866694393.1686 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "0s - loss: 29279862011.3128 - acc: 0.0000e+00 - val_loss: 33744858567.0585 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "0s - loss: 29125742589.0219 - acc: 0.0000e+00 - val_loss: 33644285068.1030 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "0s - loss: 29135346443.7264 - acc: 0.0000e+00 - val_loss: 33557741176.5960 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "0s - loss: 29145704630.3423 - acc: 0.0000e+00 - val_loss: 33569257922.1620 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "0s - loss: 29627999406.9646 - acc: 0.0000e+00 - val_loss: 33374441094.8117 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "0s - loss: 28883287517.3793 - acc: 0.0000e+00 - val_loss: 33314060014.1120 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "0s - loss: 28998647160.6308 - acc: 0.0000e+00 - val_loss: 33230604462.3785 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "0s - loss: 28946246128.6694 - acc: 0.0000e+00 - val_loss: 33176416002.3298 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "0s - loss: 28463033545.2939 - acc: 6.6098e-05 - val_loss: 33092503828.7311 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "0s - loss: 28615579105.7111 - acc: 0.0000e+00 - val_loss: 33024687159.7569 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "0s - loss: 28662973778.6259 - acc: 0.0000e+00 - val_loss: 33024953042.7864 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "0s - loss: 28480808536.5653 - acc: 0.0000e+00 - val_loss: 32850714623.6841 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "0s - loss: 28588415148.7310 - acc: 0.0000e+00 - val_loss: 32719472999.8137 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "0s - loss: 28234881920.5499 - acc: 0.0000e+00 - val_loss: 32661503004.5892 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "0s - loss: 28440447976.1073 - acc: 0.0000e+00 - val_loss: 32569332708.6744 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "0s - loss: 28070868865.6329 - acc: 0.0000e+00 - val_loss: 32472250162.3471 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "0s - loss: 27981187554.8618 - acc: 0.0000e+00 - val_loss: 32443900299.1948 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "0s - loss: 28018311472.9867 - acc: 0.0000e+00 - val_loss: 32280716201.2846 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "0s - loss: 28143127406.6812 - acc: 0.0000e+00 - val_loss: 32196231414.0885 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "0s - loss: 28342237990.3264 - acc: 0.0000e+00 - val_loss: 32262171067.8439 - val_acc: 1.5425e-04\n",
      "Epoch 201/500\n",
      "0s - loss: 27801136892.0912 - acc: 0.0000e+00 - val_loss: 32084214581.6640 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "0s - loss: 27900891960.3982 - acc: 0.0000e+00 - val_loss: 32070389550.8721 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "0s - loss: 27621311554.4663 - acc: 0.0000e+00 - val_loss: 31985717354.4594 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "0s - loss: 27298090494.8155 - acc: 0.0000e+00 - val_loss: 31888736478.7117 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "0s - loss: 27477658889.1205 - acc: 0.0000e+00 - val_loss: 31861611015.0288 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "0s - loss: 26905488481.7365 - acc: 0.0000e+00 - val_loss: 31717211064.4479 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "0s - loss: 27430460678.4131 - acc: 0.0000e+00 - val_loss: 31754247758.2650 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "0s - loss: 27476220396.6084 - acc: 0.0000e+00 - val_loss: 31730904972.3795 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "0s - loss: 27324557456.9804 - acc: 0.0000e+00 - val_loss: 31534136196.6398 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "0s - loss: 27028994603.6904 - acc: 0.0000e+00 - val_loss: 31573363887.8001 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "0s - loss: 27543959882.8422 - acc: 0.0000e+00 - val_loss: 31484071478.2564 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "0s - loss: 27014327008.0021 - acc: 0.0000e+00 - val_loss: 31377971886.7734 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "0s - loss: 27074810962.3045 - acc: 0.0000e+00 - val_loss: 31332432362.5976 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "0s - loss: 26801140621.1393 - acc: 0.0000e+00 - val_loss: 31177807464.8009 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "0s - loss: 27008982006.0504 - acc: 0.0000e+00 - val_loss: 31134970766.7487 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "0s - loss: 26795448976.6758 - acc: 0.0000e+00 - val_loss: 31076244052.1092 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "0s - loss: 26961044363.4472 - acc: 0.0000e+00 - val_loss: 31045512196.5806 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "0s - loss: 26430383008.3617 - acc: 0.0000e+00 - val_loss: 30962551509.3136 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "0s - loss: 26842264558.8081 - acc: 0.0000e+00 - val_loss: 30914586603.1504 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "0s - loss: 26585707157.4137 - acc: 0.0000e+00 - val_loss: 30821488049.2611 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "0s - loss: 26222573566.6463 - acc: 6.6098e-05 - val_loss: 30823423421.8973 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "0s - loss: 26635770047.9535 - acc: 0.0000e+00 - val_loss: 30756598044.3128 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "0s - loss: 26965896959.2047 - acc: 0.0000e+00 - val_loss: 30681125768.1148 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "0s - loss: 26582944315.9347 - acc: 0.0000e+00 - val_loss: 30841180612.0574 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "0s - loss: 26535354237.5041 - acc: 0.0000e+00 - val_loss: 30537129549.3173 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "0s - loss: 26118076689.7841 - acc: 0.0000e+00 - val_loss: 30479884330.6469 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "0s - loss: 25844649326.7827 - acc: 0.0000e+00 - val_loss: 30448667065.6326 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "0s - loss: 26364030089.8735 - acc: 0.0000e+00 - val_loss: 30424435917.8109 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "0s - loss: 25889955307.7285 - acc: 0.0000e+00 - val_loss: 30342926075.3799 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "0s - loss: 25276122955.8236 - acc: 0.0000e+00 - val_loss: 30222025914.2249 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "0s - loss: 25840626811.4228 - acc: 0.0000e+00 - val_loss: 30133625588.5880 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "0s - loss: 26107654470.1043 - acc: 0.0000e+00 - val_loss: 30035486716.5251 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "0s - loss: 25616001566.4242 - acc: 6.6098e-05 - val_loss: 30039428733.0187 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "0s - loss: 25770863542.2915 - acc: 0.0000e+00 - val_loss: 29896788702.1589 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "0s - loss: 25011056732.3218 - acc: 0.0000e+00 - val_loss: 29864016485.4839 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "0s - loss: 25295550827.1954 - acc: 0.0000e+00 - val_loss: 29798318762.9826 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "0s - loss: 25285568707.7438 - acc: 0.0000e+00 - val_loss: 29721730282.5581 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "0s - loss: 25543592630.5792 - acc: 0.0000e+00 - val_loss: 29749647067.7896 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "0s - loss: 25439790904.0598 - acc: 0.0000e+00 - val_loss: 29601389528.0383 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "0s - loss: 25286964306.6429 - acc: 0.0000e+00 - val_loss: 29602680946.3569 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "0s - loss: 25276275876.7443 - acc: 6.6098e-05 - val_loss: 29613210657.6437 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "0s - loss: 24896785013.0605 - acc: 0.0000e+00 - val_loss: 29504790355.5169 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "0s - loss: 25323519043.7523 - acc: 0.0000e+00 - val_loss: 29442850132.0697 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "0s - loss: 24821460187.9749 - acc: 6.6098e-05 - val_loss: 29436245246.1441 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "0s - loss: 25153129624.6287 - acc: 0.0000e+00 - val_loss: 29322514167.5891 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "0s - loss: 24977925924.3635 - acc: 0.0000e+00 - val_loss: 29324709931.9105 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "0s - loss: 24284197133.7907 - acc: 0.0000e+00 - val_loss: 29286787999.1757 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "0s - loss: 24567035125.0520 - acc: 0.0000e+00 - val_loss: 29242665793.6684 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "0s - loss: 24457005671.6589 - acc: 0.0000e+00 - val_loss: 29156167544.7935 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "0s - loss: 24699320418.3119 - acc: 0.0000e+00 - val_loss: 28980457665.6486 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "0s - loss: 25005866052.2937 - acc: 0.0000e+00 - val_loss: 28953164643.1541 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "0s - loss: 24058271856.4918 - acc: 0.0000e+00 - val_loss: 28953190283.4317 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "0s - loss: 23899353474.0728 - acc: 0.0000e+00 - val_loss: 28978612639.7285 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "0s - loss: 24770199395.1748 - acc: 0.0000e+00 - val_loss: 28853925577.7831 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "0s - loss: 24200715688.6192 - acc: 0.0000e+00 - val_loss: 28865934284.3498 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "0s - loss: 24389464390.5781 - acc: 0.0000e+00 - val_loss: 29127726110.8006 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "0s - loss: 23641710002.6704 - acc: 0.0000e+00 - val_loss: 28741929602.5470 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "0s - loss: 24039864469.5152 - acc: 0.0000e+00 - val_loss: 28667099841.7276 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "0s - loss: 24110974761.9137 - acc: 0.0000e+00 - val_loss: 28587116739.8599 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "0s - loss: 23730470207.2005 - acc: 0.0000e+00 - val_loss: 28568654480.1308 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "0s - loss: 23828408658.0168 - acc: 0.0000e+00 - val_loss: 28528818354.4853 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "0s - loss: 24031140853.5427 - acc: 6.6098e-05 - val_loss: 28486899624.8107 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "0s - loss: 24066602173.8552 - acc: 6.6098e-05 - val_loss: 28418264474.8320 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "0s - loss: 23544994025.6472 - acc: 0.0000e+00 - val_loss: 28447757718.0935 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "0s - loss: 23949899558.1233 - acc: 0.0000e+00 - val_loss: 28434931002.7975 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "0s - loss: 23650563562.5440 - acc: 0.0000e+00 - val_loss: 28394658559.9605 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "0s - loss: 23597916841.3130 - acc: 0.0000e+00 - val_loss: 28290538255.4398 - val_acc: 1.5425e-04\n",
      "Epoch 268/500\n",
      "0s - loss: 23387666023.1851 - acc: 6.6098e-05 - val_loss: 28197739135.0720 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "0s - loss: 23267079902.7161 - acc: 0.0000e+00 - val_loss: 28370132196.5559 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "0s - loss: 23572573497.4473 - acc: 0.0000e+00 - val_loss: 28141384278.3205 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "0s - loss: 23368856641.1802 - acc: 0.0000e+00 - val_loss: 28126440962.1323 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "0s - loss: 23674365567.8223 - acc: 0.0000e+00 - val_loss: 28083141171.2553 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "0s - loss: 23381102924.8728 - acc: 0.0000e+00 - val_loss: 28043233280.9477 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "0s - loss: 23185243184.2591 - acc: 0.0000e+00 - val_loss: 28021964211.4725 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "0s - loss: 23360539998.6738 - acc: 0.0000e+00 - val_loss: 27964938941.9368 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "0s - loss: 22966204724.1002 - acc: 0.0000e+00 - val_loss: 27918210940.5843 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "0s - loss: 22986598777.5446 - acc: 0.0000e+00 - val_loss: 27852889948.6781 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "0s - loss: 23033663704.1845 - acc: 0.0000e+00 - val_loss: 28035184469.4123 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "0s - loss: 23241462501.4169 - acc: 0.0000e+00 - val_loss: 27794530248.7170 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "0s - loss: 22184290290.0570 - acc: 0.0000e+00 - val_loss: 27754317344.7749 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "0s - loss: 22867875664.0201 - acc: 0.0000e+00 - val_loss: 27669667047.7149 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "0s - loss: 22877179250.9792 - acc: 0.0000e+00 - val_loss: 27691407393.8016 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "0s - loss: 22609158999.9730 - acc: 0.0000e+00 - val_loss: 27605032542.3761 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "0s - loss: 22641049452.3122 - acc: 0.0000e+00 - val_loss: 27589528799.8174 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "0s - loss: 22521307797.6844 - acc: 0.0000e+00 - val_loss: 27589696122.3335 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "0s - loss: 22659567328.4082 - acc: 6.6098e-05 - val_loss: 27517806905.6918 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "0s - loss: 22356581311.4628 - acc: 0.0000e+00 - val_loss: 27438121945.6178 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "0s - loss: 22394954732.4392 - acc: 0.0000e+00 - val_loss: 27464308508.5497 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "0s - loss: 22307443766.0800 - acc: 0.0000e+00 - val_loss: 27476868091.1035 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "0s - loss: 22645446106.5366 - acc: 0.0000e+00 - val_loss: 27399903476.8249 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "0s - loss: 21995414313.2368 - acc: 0.0000e+00 - val_loss: 27412458690.7543 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "0s - loss: 22246155047.8831 - acc: 0.0000e+00 - val_loss: 27378820722.5939 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "0s - loss: 22343808083.3197 - acc: 0.0000e+00 - val_loss: 27358418427.1825 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "0s - loss: 21983325980.5460 - acc: 0.0000e+00 - val_loss: 27210044130.2656 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "0s - loss: 22336036471.7002 - acc: 0.0000e+00 - val_loss: 27309918530.2212 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "0s - loss: 22016460725.9531 - acc: 6.6098e-05 - val_loss: 27344516231.6804 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "0s - loss: 21965552113.5832 - acc: 0.0000e+00 - val_loss: 27191860855.3324 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "0s - loss: 21835121440.1333 - acc: 0.0000e+00 - val_loss: 27121988520.3369 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "0s - loss: 22134143787.5381 - acc: 0.0000e+00 - val_loss: 27135462583.3818 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "0s - loss: 22055428238.5437 - acc: 0.0000e+00 - val_loss: 27080266124.7743 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "0s - loss: 21438919544.2924 - acc: 0.0000e+00 - val_loss: 27064601247.9260 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "0s - loss: 22171370794.0829 - acc: 0.0000e+00 - val_loss: 27051483381.4567 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "0s - loss: 21974924686.4084 - acc: 0.0000e+00 - val_loss: 26962831318.3008 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "0s - loss: 22107130172.7638 - acc: 0.0000e+00 - val_loss: 26871626410.0349 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "0s - loss: 21716498834.6894 - acc: 0.0000e+00 - val_loss: 26909055246.7290 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "0s - loss: 21448911875.8580 - acc: 0.0000e+00 - val_loss: 26823884443.0295 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "0s - loss: 21213742392.4997 - acc: 6.6098e-05 - val_loss: 26910971752.3665 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "0s - loss: 22186552883.4741 - acc: 0.0000e+00 - val_loss: 26827887936.7996 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "0s - loss: 21308983115.4175 - acc: 0.0000e+00 - val_loss: 26752337125.8195 - val_acc: 1.5425e-04\n",
      "Epoch 310/500\n",
      "0s - loss: 21703617902.3766 - acc: 0.0000e+00 - val_loss: 26766304064.7207 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "0s - loss: 21561705252.1605 - acc: 0.0000e+00 - val_loss: 26803142726.1305 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "0s - loss: 21265605229.7505 - acc: 0.0000e+00 - val_loss: 26660108512.9230 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "0s - loss: 21126341546.6497 - acc: 0.0000e+00 - val_loss: 26787565564.2092 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "0s - loss: 20894468501.0922 - acc: 6.6098e-05 - val_loss: 26644510843.5181 - val_acc: 1.5425e-04\n",
      "Epoch 315/500\n",
      "0s - loss: 21194302915.6592 - acc: 0.0000e+00 - val_loss: 26675559187.8624 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "0s - loss: 21693230903.1122 - acc: 0.0000e+00 - val_loss: 26562211764.1832 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "0s - loss: 21257245130.9015 - acc: 0.0000e+00 - val_loss: 26557956928.0888 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "0s - loss: 21172682824.0164 - acc: 0.0000e+00 - val_loss: 26508061069.0902 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "0s - loss: 21159524682.1654 - acc: 0.0000e+00 - val_loss: 26662881998.3637 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "0s - loss: 20952984336.8027 - acc: 0.0000e+00 - val_loss: 26516600735.6495 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "0s - loss: 21080155563.9696 - acc: 0.0000e+00 - val_loss: 26492052551.8680 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "0s - loss: 21249033221.3471 - acc: 0.0000e+00 - val_loss: 26449622067.9661 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "0s - loss: 20581217272.4870 - acc: 6.6098e-05 - val_loss: 26413636441.6770 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "0s - loss: 20686669130.0977 - acc: 0.0000e+00 - val_loss: 26429228836.1314 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "0s - loss: 21224011561.3722 - acc: 0.0000e+00 - val_loss: 26338168271.5878 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "0s - loss: 21340977173.8621 - acc: 0.0000e+00 - val_loss: 26290076684.4782 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "0s - loss: 21294382809.1660 - acc: 0.0000e+00 - val_loss: 26390561429.1853 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "0s - loss: 21265079764.4450 - acc: 0.0000e+00 - val_loss: 26366084580.7534 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "0s - loss: 20753438476.9447 - acc: 0.0000e+00 - val_loss: 26302203642.1163 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "0s - loss: 20832315986.9475 - acc: 0.0000e+00 - val_loss: 26283891514.4026 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "0s - loss: 20996642988.2911 - acc: 0.0000e+00 - val_loss: 26231114628.9557 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "0s - loss: 20563284747.9971 - acc: 0.0000e+00 - val_loss: 26246324683.9550 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "0s - loss: 20793053564.1166 - acc: 0.0000e+00 - val_loss: 26211620122.2594 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "0s - loss: 20833233263.7303 - acc: 0.0000e+00 - val_loss: 26306305525.4962 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "0s - loss: 20810738941.8849 - acc: 0.0000e+00 - val_loss: 26400937976.1024 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "0s - loss: 20453260074.5905 - acc: 0.0000e+00 - val_loss: 26191891761.0045 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "0s - loss: 20238428290.9020 - acc: 0.0000e+00 - val_loss: 26199739473.0292 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "0s - loss: 20623313603.1685 - acc: 0.0000e+00 - val_loss: 26255988279.8359 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "0s - loss: 20886118227.8781 - acc: 0.0000e+00 - val_loss: 26213248300.5818 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "0s - loss: 21192148024.1105 - acc: 6.6098e-05 - val_loss: 26201510992.7132 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "0s - loss: 20732815790.7447 - acc: 0.0000e+00 - val_loss: 26166374644.8249 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "0s - loss: 20155224774.6881 - acc: 0.0000e+00 - val_loss: 26095706660.4078 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "0s - loss: 20542615307.7940 - acc: 0.0000e+00 - val_loss: 26140343907.4305 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "0s - loss: 20173961772.7733 - acc: 0.0000e+00 - val_loss: 26156561042.9739 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "0s - loss: 20342961990.6796 - acc: 0.0000e+00 - val_loss: 26045494256.9946 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "0s - loss: 20332542202.2299 - acc: 0.0000e+00 - val_loss: 26079876721.0143 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "0s - loss: 20518171226.1220 - acc: 0.0000e+00 - val_loss: 26099887936.8786 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "0s - loss: 20315393022.7140 - acc: 0.0000e+00 - val_loss: 26119851716.4128 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "0s - loss: 20259191444.3984 - acc: 0.0000e+00 - val_loss: 26022681015.7372 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "0s - loss: 20642835228.6475 - acc: 0.0000e+00 - val_loss: 26207591392.2517 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "0s - loss: 20030056243.2542 - acc: 0.0000e+00 - val_loss: 26016132898.8678 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "0s - loss: 19833656869.5311 - acc: 0.0000e+00 - val_loss: 26077143238.7031 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "0s - loss: 20500058465.4489 - acc: 0.0000e+00 - val_loss: 26051966039.3472 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "0s - loss: 20550608441.0243 - acc: 0.0000e+00 - val_loss: 26016831152.8268 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "0s - loss: 20166133833.0993 - acc: 0.0000e+00 - val_loss: 26019155618.6111 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "0s - loss: 19909361234.6090 - acc: 6.6098e-05 - val_loss: 26022709018.0225 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "0s - loss: 19852325831.2126 - acc: 6.6098e-05 - val_loss: 25958515709.3148 - val_acc: 1.5425e-04\n",
      "Epoch 358/500\n",
      "0s - loss: 19755757003.6460 - acc: 0.0000e+00 - val_loss: 25956165835.1257 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "0s - loss: 19801928252.6115 - acc: 0.0000e+00 - val_loss: 26069116333.7862 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "0s - loss: 19966214508.3461 - acc: 0.0000e+00 - val_loss: 25903886058.9530 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "0s - loss: 20207189211.0950 - acc: 0.0000e+00 - val_loss: 25820935312.2098 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "0s - loss: 20116628282.2257 - acc: 0.0000e+00 - val_loss: 25889914760.9045 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "0s - loss: 19823255136.8228 - acc: 0.0000e+00 - val_loss: 25826881352.7762 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "0s - loss: 19594802702.7214 - acc: 0.0000e+00 - val_loss: 26198260818.9246 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "0s - loss: 19886393812.3096 - acc: 0.0000e+00 - val_loss: 25847800892.4954 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "0s - loss: 19661860037.8420 - acc: 0.0000e+00 - val_loss: 25781680248.9909 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "0s - loss: 19804469739.8638 - acc: 6.6098e-05 - val_loss: 25934029554.3767 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "0s - loss: 20156520364.0711 - acc: 0.0000e+00 - val_loss: 25793054236.0364 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "0s - loss: 19911838741.7267 - acc: 0.0000e+00 - val_loss: 25911310003.9858 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "0s - loss: 19695751562.9395 - acc: 0.0000e+00 - val_loss: 25738481187.9340 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "0s - loss: 19908360172.0330 - acc: 0.0000e+00 - val_loss: 25728823525.0298 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "0s - loss: 19622020059.6534 - acc: 0.0000e+00 - val_loss: 25720565210.6445 - val_acc: 1.5425e-04\n",
      "Epoch 373/500\n",
      "0s - loss: 19749751778.8279 - acc: 0.0000e+00 - val_loss: 25719234353.7153 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "0s - loss: 19405753296.6208 - acc: 6.6098e-05 - val_loss: 25984456547.9439 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "0s - loss: 19940937101.8500 - acc: 0.0000e+00 - val_loss: 25791564508.8953 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "0s - loss: 19233115307.2420 - acc: 0.0000e+00 - val_loss: 25725160955.4984 - val_acc: 1.5425e-04\n",
      "Epoch 377/500\n",
      "0s - loss: 19294499534.9456 - acc: 0.0000e+00 - val_loss: 25698121775.7014 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "0s - loss: 19720310504.9365 - acc: 0.0000e+00 - val_loss: 25712520714.0299 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "0s - loss: 19742712550.8383 - acc: 0.0000e+00 - val_loss: 25686206935.3275 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "0s - loss: 19380586666.7005 - acc: 0.0000e+00 - val_loss: 25636029360.8663 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "0s - loss: 19734677615.2734 - acc: 0.0000e+00 - val_loss: 25667822310.6883 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "0s - loss: 19592322820.2810 - acc: 0.0000e+00 - val_loss: 25656827554.6111 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "0s - loss: 19222049245.3117 - acc: 0.0000e+00 - val_loss: 25671302469.8541 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "0s - loss: 19171386519.2412 - acc: 0.0000e+00 - val_loss: 25644984195.5342 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "0s - loss: 19383781871.0450 - acc: 0.0000e+00 - val_loss: 25590185377.1501 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "0s - loss: 19550262932.5338 - acc: 0.0000e+00 - val_loss: 25481633255.9124 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "0s - loss: 19538900005.1927 - acc: 0.0000e+00 - val_loss: 25501118073.5437 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "0s - loss: 19072410705.1538 - acc: 6.6098e-05 - val_loss: 25502435264.5035 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "0s - loss: 19080247079.8155 - acc: 0.0000e+00 - val_loss: 25548331438.5760 - val_acc: 1.5425e-04\n",
      "Epoch 390/500\n",
      "0s - loss: 18892732798.6209 - acc: 0.0000e+00 - val_loss: 25591888701.2457 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "0s - loss: 19397598975.1370 - acc: 0.0000e+00 - val_loss: 25512409413.6961 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "0s - loss: 19373727809.2479 - acc: 0.0000e+00 - val_loss: 25465313913.3858 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "0s - loss: 18934353260.2107 - acc: 0.0000e+00 - val_loss: 25411295947.5206 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "0s - loss: 19162588149.1028 - acc: 0.0000e+00 - val_loss: 25541125479.6557 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "0s - loss: 19158753568.2009 - acc: 0.0000e+00 - val_loss: 25408142687.4422 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "0s - loss: 18989062691.5682 - acc: 0.0000e+00 - val_loss: 25415036710.6586 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "0s - loss: 19073299919.5040 - acc: 0.0000e+00 - val_loss: 25500153543.2559 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "0s - loss: 19092720130.4028 - acc: 0.0000e+00 - val_loss: 25401340174.0972 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "0s - loss: 19265357543.5151 - acc: 0.0000e+00 - val_loss: 25373177527.4607 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "0s - loss: 19053017175.7869 - acc: 0.0000e+00 - val_loss: 25324335460.0228 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "0s - loss: 19309897437.6332 - acc: 0.0000e+00 - val_loss: 25343643573.1310 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "0s - loss: 18572580495.4913 - acc: 0.0000e+00 - val_loss: 25359069657.5388 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "0s - loss: 19145219948.2446 - acc: 0.0000e+00 - val_loss: 25253938103.1843 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "0s - loss: 19055162242.5805 - acc: 0.0000e+00 - val_loss: 25239637549.4111 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "0s - loss: 18823956080.3902 - acc: 0.0000e+00 - val_loss: 25387209744.9008 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "0s - loss: 19256007130.0628 - acc: 0.0000e+00 - val_loss: 25337739786.5038 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "0s - loss: 18963643362.8279 - acc: 0.0000e+00 - val_loss: 25239277928.7614 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "0s - loss: 18152970197.3587 - acc: 0.0000e+00 - val_loss: 25263564031.0918 - val_acc: 1.5425e-04\n",
      "Epoch 409/500\n",
      "0s - loss: 19385617135.9757 - acc: 0.0000e+00 - val_loss: 25305053524.7015 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "0s - loss: 19266653411.4879 - acc: 0.0000e+00 - val_loss: 25114135779.1343 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "0s - loss: 18705503833.1406 - acc: 0.0000e+00 - val_loss: 25236719472.1061 - val_acc: 1.5425e-04\n",
      "Epoch 412/500\n",
      "0s - loss: 19156690276.9008 - acc: 0.0000e+00 - val_loss: 25248963714.1521 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "0s - loss: 19174696127.8858 - acc: 0.0000e+00 - val_loss: 25111197727.9062 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "0s - loss: 18956436677.9774 - acc: 0.0000e+00 - val_loss: 25214594855.4484 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "0s - loss: 19057285717.8579 - acc: 0.0000e+00 - val_loss: 25143927106.5371 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "0s - loss: 18814293466.9089 - acc: 0.0000e+00 - val_loss: 25115240274.7271 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "0s - loss: 18896991466.3917 - acc: 0.0000e+00 - val_loss: 25185769897.6795 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "0s - loss: 18667322474.1294 - acc: 0.0000e+00 - val_loss: 25100049978.5211 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "0s - loss: 19281857571.2637 - acc: 0.0000e+00 - val_loss: 25126625711.2078 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "0s - loss: 19030228253.4259 - acc: 0.0000e+00 - val_loss: 25015551117.3666 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "0s - loss: 18882811437.7548 - acc: 0.0000e+00 - val_loss: 25011295950.8376 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "0s - loss: 18307639142.0176 - acc: 0.0000e+00 - val_loss: 25040333854.6426 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "0s - loss: 18624061936.1280 - acc: 0.0000e+00 - val_loss: 24956080899.4354 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "0s - loss: 18593197662.2508 - acc: 0.0000e+00 - val_loss: 24989116439.0609 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "0s - loss: 18484790918.0493 - acc: 0.0000e+00 - val_loss: 25023161498.1607 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "0s - loss: 18821382673.2257 - acc: 0.0000e+00 - val_loss: 25020858495.3090 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "0s - loss: 18524794771.9754 - acc: 0.0000e+00 - val_loss: 25003667854.6698 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "0s - loss: 18570401816.2311 - acc: 0.0000e+00 - val_loss: 25066351123.8229 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "0s - loss: 18379193296.6885 - acc: 0.0000e+00 - val_loss: 25096747270.3576 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "0s - loss: 18602452557.8034 - acc: 0.0000e+00 - val_loss: 25006869878.6611 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "0s - loss: 18338085048.5082 - acc: 6.6098e-05 - val_loss: 25149759738.6691 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "0s - loss: 18711580399.0958 - acc: 0.0000e+00 - val_loss: 24967596294.3576 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "0s - loss: 18458227901.0092 - acc: 6.6098e-05 - val_loss: 24966715162.9702 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "0s - loss: 18371545033.9877 - acc: 0.0000e+00 - val_loss: 24933056143.3410 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "0s - loss: 18662107433.9475 - acc: 6.6098e-05 - val_loss: 25005918117.6517 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "0s - loss: 18571733769.7297 - acc: 0.0000e+00 - val_loss: 24981847500.9027 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "0s - loss: 18354034728.8476 - acc: 0.0000e+00 - val_loss: 24874523065.3167 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "0s - loss: 18468905723.7528 - acc: 0.0000e+00 - val_loss: 24880341727.5804 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "0s - loss: 18469304018.4652 - acc: 0.0000e+00 - val_loss: 24801997005.1791 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "0s - loss: 18525559349.9785 - acc: 0.0000e+00 - val_loss: 24853868803.1985 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "0s - loss: 18487430245.1884 - acc: 0.0000e+00 - val_loss: 24960557014.3008 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "0s - loss: 17869456803.3060 - acc: 0.0000e+00 - val_loss: 24761767257.9139 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "0s - loss: 18427538880.4103 - acc: 0.0000e+00 - val_loss: 24731330265.7362 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "0s - loss: 18429045568.1142 - acc: 0.0000e+00 - val_loss: 24738485967.7853 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "0s - loss: 18179039357.4872 - acc: 0.0000e+00 - val_loss: 24748262225.4635 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "0s - loss: 18325089844.6924 - acc: 0.0000e+00 - val_loss: 24690323449.2081 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "0s - loss: 18579684139.4704 - acc: 0.0000e+00 - val_loss: 24812650412.2857 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "0s - loss: 18535466098.9961 - acc: 0.0000e+00 - val_loss: 24706364212.4004 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "0s - loss: 18376678505.4526 - acc: 0.0000e+00 - val_loss: 24736700766.9684 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "0s - loss: 18049422408.5579 - acc: 0.0000e+00 - val_loss: 24734415344.9156 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "0s - loss: 17931468371.4212 - acc: 0.0000e+00 - val_loss: 24674103075.9735 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "0s - loss: 17882120786.7444 - acc: 0.0000e+00 - val_loss: 24888214055.5669 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "0s - loss: 18531519338.0448 - acc: 0.0000e+00 - val_loss: 24603373829.4098 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "0s - loss: 18221273472.8545 - acc: 0.0000e+00 - val_loss: 24644373814.6907 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "0s - loss: 17979339645.7072 - acc: 0.0000e+00 - val_loss: 24579782824.6923 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "0s - loss: 17981877680.5045 - acc: 0.0000e+00 - val_loss: 24624725507.3960 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "0s - loss: 18385900727.5606 - acc: 0.0000e+00 - val_loss: 24568737620.4646 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "0s - loss: 17966066959.3475 - acc: 0.0000e+00 - val_loss: 24615107996.2536 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "0s - loss: 17907320376.7535 - acc: 0.0000e+00 - val_loss: 24616643257.8300 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "0s - loss: 17964870802.7402 - acc: 0.0000e+00 - val_loss: 24550899591.9568 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "0s - loss: 18502650657.5208 - acc: 0.0000e+00 - val_loss: 24571809142.6611 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "0s - loss: 18047040376.9016 - acc: 0.0000e+00 - val_loss: 24542720084.5041 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "0s - loss: 17859137794.4197 - acc: 0.0000e+00 - val_loss: 24516321041.4931 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "0s - loss: 18090127932.4085 - acc: 0.0000e+00 - val_loss: 24560544287.5113 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "0s - loss: 17925656511.2935 - acc: 0.0000e+00 - val_loss: 24501265969.9917 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "0s - loss: 18235205755.5920 - acc: 0.0000e+00 - val_loss: 24419802411.4762 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "0s - loss: 18331652210.3193 - acc: 0.0000e+00 - val_loss: 24494676216.2999 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "0s - loss: 17905476418.6862 - acc: 0.0000e+00 - val_loss: 24518224263.5619 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "0s - loss: 17501146895.8213 - acc: 0.0000e+00 - val_loss: 24460314753.6782 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "0s - loss: 18028355950.8843 - acc: 0.0000e+00 - val_loss: 24367440915.2701 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "0s - loss: 17977663443.1251 - acc: 0.0000e+00 - val_loss: 24423296082.6087 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "0s - loss: 17411052651.0093 - acc: 0.0000e+00 - val_loss: 24508048055.6187 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "0s - loss: 17821046977.3748 - acc: 0.0000e+00 - val_loss: 24505549450.7605 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "0s - loss: 17720917508.9071 - acc: 0.0000e+00 - val_loss: 24437119568.7922 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "0s - loss: 17657232767.1624 - acc: 0.0000e+00 - val_loss: 24502600542.4156 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "0s - loss: 17478561856.9772 - acc: 0.0000e+00 - val_loss: 24446331152.9403 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "0s - loss: 17379403421.4682 - acc: 0.0000e+00 - val_loss: 24328683589.6566 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "0s - loss: 17932758738.8036 - acc: 0.0000e+00 - val_loss: 24429660581.8886 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "0s - loss: 17414955933.3836 - acc: 0.0000e+00 - val_loss: 24368685195.4712 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "0s - loss: 17781734420.2377 - acc: 0.0000e+00 - val_loss: 24597608619.6933 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "0s - loss: 17311586562.6905 - acc: 0.0000e+00 - val_loss: 24377832748.4239 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "0s - loss: 17826944631.2264 - acc: 0.0000e+00 - val_loss: 24354764440.9761 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "0s - loss: 17863185376.7974 - acc: 0.0000e+00 - val_loss: 24321609058.2854 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "0s - loss: 17570870866.2029 - acc: 0.0000e+00 - val_loss: 24366969804.5078 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "0s - loss: 17913623050.9311 - acc: 6.6098e-05 - val_loss: 24275002660.0524 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "0s - loss: 17700164967.2021 - acc: 0.0000e+00 - val_loss: 24318035089.4734 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "0s - loss: 17974152454.6839 - acc: 0.0000e+00 - val_loss: 24354024490.1731 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "0s - loss: 17648654550.6955 - acc: 0.0000e+00 - val_loss: 24450293584.5158 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "0s - loss: 17537274811.3002 - acc: 0.0000e+00 - val_loss: 24436694873.8349 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "0s - loss: 17510292217.9253 - acc: 0.0000e+00 - val_loss: 24412901125.4888 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "0s - loss: 17634667102.9276 - acc: 0.0000e+00 - val_loss: 24248608953.4351 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "0s - loss: 17716872181.7796 - acc: 0.0000e+00 - val_loss: 24309463223.3818 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "0s - loss: 17725831982.8547 - acc: 0.0000e+00 - val_loss: 24421685642.5630 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "0s - loss: 17463749390.5014 - acc: 0.0000e+00 - val_loss: 24340877388.9224 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "0s - loss: 17408420741.9647 - acc: 0.0000e+00 - val_loss: 24362998983.9667 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "0s - loss: 17631691873.5335 - acc: 0.0000e+00 - val_loss: 24437199172.7484 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "0s - loss: 17216173774.2011 - acc: 6.6098e-05 - val_loss: 24364348168.4899 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "0s - loss: 17268564099.1727 - acc: 0.0000e+00 - val_loss: 24242757522.6975 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "0s - loss: 17439063059.6962 - acc: 0.0000e+00 - val_loss: 24428339355.2664 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "0s - loss: 17724491146.5334 - acc: 0.0000e+00 - val_loss: 24299659291.4836 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(arr_x_train, arr_y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2, # Change it to 2, if wished to observe execution\n",
    "    validation_data=(arr_x_valid, arr_y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "7a410744-5fb1-46de-9f03-8375ca5cb995",
    "_uuid": "8535f5484e9e0e34523d9adcd3ef9b6fc7cf336f",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 80)                1520      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                2420      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 13,881\n",
      "Trainable params: 13,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = basic_model_3(arr_x_train.shape[1], arr_y_train.shape[1])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "52230370-92b1-4f9c-8b7f-4f82208a7841",
    "_uuid": "bb70d9a24530fe50cfaf69daa90714dc53922bec",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15129 samples, validate on 6483 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 407817466565.6051 - acc: 0.0000e+00 - val_loss: 377658208161.8608 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "0s - loss: 215426580693.3418 - acc: 0.0000e+00 - val_loss: 126037314792.3468 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "0s - loss: 117002481547.7179 - acc: 0.0000e+00 - val_loss: 119223133867.1405 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "0s - loss: 113037292622.1757 - acc: 0.0000e+00 - val_loss: 115939349261.5443 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "0s - loss: 109927861776.8196 - acc: 0.0000e+00 - val_loss: 112325252639.5113 - val_acc: 1.5425e-04\n",
      "Epoch 6/500\n",
      "0s - loss: 106108117316.3445 - acc: 0.0000e+00 - val_loss: 107621949613.1149 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "0s - loss: 101044416200.3802 - acc: 0.0000e+00 - val_loss: 102483032772.5707 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "0s - loss: 95417381306.9279 - acc: 0.0000e+00 - val_loss: 97196786101.2099 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "0s - loss: 89092732979.0342 - acc: 0.0000e+00 - val_loss: 90927897221.3901 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "0s - loss: 83301470357.1768 - acc: 0.0000e+00 - val_loss: 84791777503.3435 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "0s - loss: 78098402210.6630 - acc: 0.0000e+00 - val_loss: 79202398893.5098 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "0s - loss: 72589406053.9499 - acc: 0.0000e+00 - val_loss: 72987678293.8467 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "0s - loss: 66471531076.4630 - acc: 0.0000e+00 - val_loss: 65400800669.9911 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "0s - loss: 58172658251.7729 - acc: 0.0000e+00 - val_loss: 56677082761.6548 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "0s - loss: 53123808406.5982 - acc: 0.0000e+00 - val_loss: 51610457522.2089 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "0s - loss: 49352548392.8815 - acc: 0.0000e+00 - val_loss: 48503561543.7495 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "0s - loss: 47270816984.3876 - acc: 6.6098e-05 - val_loss: 46454470854.7031 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "0s - loss: 45679861404.2499 - acc: 0.0000e+00 - val_loss: 44840131496.0210 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "0s - loss: 45235665283.8326 - acc: 0.0000e+00 - val_loss: 44142648750.7339 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "0s - loss: 44471876536.5928 - acc: 0.0000e+00 - val_loss: 43291596661.9503 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "0s - loss: 43745913084.5989 - acc: 0.0000e+00 - val_loss: 42364312673.7720 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "0s - loss: 43218025559.2454 - acc: 0.0000e+00 - val_loss: 41684886892.7102 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "0s - loss: 42652728137.5901 - acc: 0.0000e+00 - val_loss: 41031023987.9759 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "0s - loss: 42368710004.7390 - acc: 0.0000e+00 - val_loss: 40558421268.2573 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "0s - loss: 41427689813.5364 - acc: 0.0000e+00 - val_loss: 39920894164.9187 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "0s - loss: 40718918562.7983 - acc: 0.0000e+00 - val_loss: 39458658682.7679 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "0s - loss: 40227836321.7492 - acc: 0.0000e+00 - val_loss: 38756114582.3699 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "0s - loss: 40253008615.3120 - acc: 0.0000e+00 - val_loss: 38271734617.9929 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "0s - loss: 39564570155.6227 - acc: 0.0000e+00 - val_loss: 37990508553.1612 - val_acc: 1.5425e-04\n",
      "Epoch 30/500\n",
      "0s - loss: 38798336231.8874 - acc: 0.0000e+00 - val_loss: 37990975920.4714 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "0s - loss: 38205263561.4632 - acc: 0.0000e+00 - val_loss: 36508275895.6977 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "0s - loss: 36251887024.2337 - acc: 0.0000e+00 - val_loss: 35989425062.7574 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "0s - loss: 36181335922.1331 - acc: 0.0000e+00 - val_loss: 35438270912.5824 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "0s - loss: 36274911084.0415 - acc: 0.0000e+00 - val_loss: 34904438381.5394 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "0s - loss: 36180915014.6119 - acc: 0.0000e+00 - val_loss: 34522048762.8271 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "0s - loss: 35450168427.4154 - acc: 0.0000e+00 - val_loss: 33810618629.8837 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "0s - loss: 33635537984.0973 - acc: 0.0000e+00 - val_loss: 33322694142.6574 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "0s - loss: 34179540579.1918 - acc: 6.6098e-05 - val_loss: 32459661234.6037 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "0s - loss: 34132252055.7996 - acc: 0.0000e+00 - val_loss: 32013341493.9799 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "0s - loss: 32992010883.5450 - acc: 0.0000e+00 - val_loss: 31677700735.7038 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "0s - loss: 32625296414.9995 - acc: 0.0000e+00 - val_loss: 31386398998.9425 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "0s - loss: 31437426587.2853 - acc: 0.0000e+00 - val_loss: 31212000249.5240 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "0s - loss: 32405592925.2186 - acc: 0.0000e+00 - val_loss: 30852041468.1697 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "0s - loss: 31178541952.6853 - acc: 0.0000e+00 - val_loss: 30068688382.9733 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "0s - loss: 30444839139.3525 - acc: 0.0000e+00 - val_loss: 29650093966.9067 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "0s - loss: 30818503361.5441 - acc: 0.0000e+00 - val_loss: 29484751637.4419 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "0s - loss: 30758856963.0289 - acc: 0.0000e+00 - val_loss: 29307427635.7686 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "0s - loss: 30284855453.1636 - acc: 0.0000e+00 - val_loss: 29508520517.2618 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "0s - loss: 29572102448.0391 - acc: 6.6098e-05 - val_loss: 28619876011.4564 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "0s - loss: 30048882950.4131 - acc: 0.0000e+00 - val_loss: 28503454385.3006 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "0s - loss: 30470581310.4729 - acc: 0.0000e+00 - val_loss: 28391267535.7063 - val_acc: 1.5425e-04\n",
      "Epoch 52/500\n",
      "0s - loss: 29550754243.7269 - acc: 0.0000e+00 - val_loss: 28486210786.9764 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "0s - loss: 28381388230.0958 - acc: 0.0000e+00 - val_loss: 28031629326.5315 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 28259023981.4460 - acc: 0.0000e+00 - val_loss: 27717709093.9479 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "0s - loss: 29649883444.6417 - acc: 0.0000e+00 - val_loss: 28080996730.7679 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "0s - loss: 28468042717.1424 - acc: 0.0000e+00 - val_loss: 27276026139.0492 - val_acc: 1.5425e-04\n",
      "Epoch 57/500\n",
      "0s - loss: 29401248058.9363 - acc: 0.0000e+00 - val_loss: 27286721033.5561 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "0s - loss: 27833967257.6102 - acc: 0.0000e+00 - val_loss: 27288591698.8061 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "0s - loss: 28022078302.1662 - acc: 0.0000e+00 - val_loss: 27455287859.5712 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "0s - loss: 28585358349.8753 - acc: 0.0000e+00 - val_loss: 26787184639.3682 - val_acc: 1.5425e-04\n",
      "Epoch 61/500\n",
      "0s - loss: 27305402735.6626 - acc: 0.0000e+00 - val_loss: 26600497598.6870 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 27797099627.9569 - acc: 0.0000e+00 - val_loss: 26822955428.1512 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "0s - loss: 26984749412.1563 - acc: 0.0000e+00 - val_loss: 26869045411.3219 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "0s - loss: 26977183644.2329 - acc: 0.0000e+00 - val_loss: 27189072601.7362 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "0s - loss: 27164836772.7612 - acc: 0.0000e+00 - val_loss: 25993995862.4785 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "0s - loss: 27050034519.7700 - acc: 0.0000e+00 - val_loss: 26278858488.5368 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "0s - loss: 26704545796.3318 - acc: 0.0000e+00 - val_loss: 25655532625.6610 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "0s - loss: 26674798960.3395 - acc: 0.0000e+00 - val_loss: 26354226696.4504 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "0s - loss: 26077597956.4503 - acc: 0.0000e+00 - val_loss: 25937467446.3353 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "0s - loss: 27211484378.6889 - acc: 6.6098e-05 - val_loss: 25809459310.2502 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "0s - loss: 26235872907.4641 - acc: 0.0000e+00 - val_loss: 25467928471.7520 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "0s - loss: 26266096676.7527 - acc: 0.0000e+00 - val_loss: 25531440411.2072 - val_acc: 1.5425e-04\n",
      "Epoch 73/500\n",
      "0s - loss: 25668999184.5489 - acc: 0.0000e+00 - val_loss: 25457948506.1509 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "0s - loss: 24803782374.2291 - acc: 0.0000e+00 - val_loss: 25348881827.9932 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "0s - loss: 25366075185.0206 - acc: 0.0000e+00 - val_loss: 25119154595.5194 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "0s - loss: 26190858923.9527 - acc: 6.6098e-05 - val_loss: 25240327671.3916 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "0s - loss: 25715471854.9096 - acc: 0.0000e+00 - val_loss: 25368742991.4496 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "0s - loss: 25206205560.5462 - acc: 0.0000e+00 - val_loss: 25255291457.1550 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "0s - loss: 25637417011.4403 - acc: 6.6098e-05 - val_loss: 24910859737.0649 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "0s - loss: 24816407914.1125 - acc: 0.0000e+00 - val_loss: 24976377553.0489 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "0s - loss: 24998215786.5355 - acc: 0.0000e+00 - val_loss: 24627023880.5294 - val_acc: 1.5425e-04\n",
      "Epoch 82/500\n",
      "0s - loss: 24740834564.2472 - acc: 0.0000e+00 - val_loss: 25486574790.2292 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "0s - loss: 25630584004.3530 - acc: 0.0000e+00 - val_loss: 24840360410.9604 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "0s - loss: 25260410824.3633 - acc: 0.0000e+00 - val_loss: 24883413894.8512 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "0s - loss: 24682609646.3343 - acc: 0.0000e+00 - val_loss: 24377975705.1735 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "0s - loss: 25077446551.1566 - acc: 0.0000e+00 - val_loss: 24429230614.5081 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "0s - loss: 25063558249.3849 - acc: 0.0000e+00 - val_loss: 24675773552.1456 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "0s - loss: 24568158101.0584 - acc: 0.0000e+00 - val_loss: 24467212540.7225 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "0s - loss: 25218555807.6172 - acc: 0.0000e+00 - val_loss: 24367712658.9344 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "0s - loss: 25492000917.0414 - acc: 0.0000e+00 - val_loss: 24496516277.1704 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "0s - loss: 25332785855.7843 - acc: 0.0000e+00 - val_loss: 24377095727.1485 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "0s - loss: 24586135679.1116 - acc: 0.0000e+00 - val_loss: 24445073812.1981 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "0s - loss: 24488444440.4680 - acc: 0.0000e+00 - val_loss: 24762857290.6716 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "0s - loss: 24011582559.8414 - acc: 0.0000e+00 - val_loss: 24924763501.0261 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "0s - loss: 24168683272.8159 - acc: 0.0000e+00 - val_loss: 24195648046.6747 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "0s - loss: 24723317496.2332 - acc: 0.0000e+00 - val_loss: 24156592828.5152 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "0s - loss: 24568948218.2130 - acc: 0.0000e+00 - val_loss: 24140386266.0916 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "0s - loss: 23528376504.7112 - acc: 0.0000e+00 - val_loss: 24105167970.4038 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "0s - loss: 23989775909.1250 - acc: 0.0000e+00 - val_loss: 24441676862.5488 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "0s - loss: 24419895612.6285 - acc: 0.0000e+00 - val_loss: 23939794123.1257 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "0s - loss: 24149059552.0529 - acc: 0.0000e+00 - val_loss: 23987652945.5425 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "0s - loss: 23598280644.7083 - acc: 0.0000e+00 - val_loss: 24125230605.1890 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "0s - loss: 23793138388.0219 - acc: 0.0000e+00 - val_loss: 23794315945.7190 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "0s - loss: 24237215817.8439 - acc: 0.0000e+00 - val_loss: 24026556796.5053 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "0s - loss: 24672648769.1464 - acc: 0.0000e+00 - val_loss: 23802390738.2335 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "0s - loss: 23348453959.7118 - acc: 0.0000e+00 - val_loss: 23912613334.3798 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "0s - loss: 22782602476.5576 - acc: 0.0000e+00 - val_loss: 23763309966.3538 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "0s - loss: 23026905234.4694 - acc: 0.0000e+00 - val_loss: 23797313566.8006 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "0s - loss: 22701326341.4825 - acc: 0.0000e+00 - val_loss: 23666949159.6458 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "0s - loss: 23416157197.1985 - acc: 0.0000e+00 - val_loss: 23849405022.5340 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "0s - loss: 23210305741.0843 - acc: 0.0000e+00 - val_loss: 23878524332.5226 - val_acc: 1.5425e-04\n",
      "Epoch 112/500\n",
      "0s - loss: 22708056047.7557 - acc: 0.0000e+00 - val_loss: 23733923491.7168 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "0s - loss: 23383509701.6051 - acc: 0.0000e+00 - val_loss: 23625225469.9861 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "0s - loss: 23347313839.6415 - acc: 6.6098e-05 - val_loss: 23945828346.3137 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "0s - loss: 23549621856.8228 - acc: 0.0000e+00 - val_loss: 23892009408.8983 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "0s - loss: 22795286781.8172 - acc: 0.0000e+00 - val_loss: 23952749369.1390 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "0s - loss: 22563879213.5010 - acc: 0.0000e+00 - val_loss: 23875838832.1061 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "0s - loss: 22858823698.4102 - acc: 0.0000e+00 - val_loss: 23760974343.6607 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "0s - loss: 22718204015.4088 - acc: 0.0000e+00 - val_loss: 23713563548.8064 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "0s - loss: 22746300993.6202 - acc: 0.0000e+00 - val_loss: 23824973392.9502 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "0s - loss: 22846505269.7246 - acc: 0.0000e+00 - val_loss: 23879819792.6639 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "0s - loss: 22119023907.5175 - acc: 0.0000e+00 - val_loss: 23943880760.2308 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "0s - loss: 22490892511.7652 - acc: 0.0000e+00 - val_loss: 23607680924.6485 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "0s - loss: 22395886478.2222 - acc: 6.6098e-05 - val_loss: 23691612852.7756 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "0s - loss: 22571109559.6621 - acc: 0.0000e+00 - val_loss: 23679425001.4919 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "0s - loss: 22811520112.9656 - acc: 0.0000e+00 - val_loss: 23752104820.0549 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "0s - loss: 22457424688.6821 - acc: 0.0000e+00 - val_loss: 24067341952.3356 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "0s - loss: 23347718902.4734 - acc: 0.0000e+00 - val_loss: 23668521680.8909 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "0s - loss: 22821806626.4853 - acc: 0.0000e+00 - val_loss: 23868564804.1166 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "0s - loss: 22698305347.4308 - acc: 0.0000e+00 - val_loss: 23555725821.0779 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "0s - loss: 22634128814.1693 - acc: 6.6098e-05 - val_loss: 23584019743.4719 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "0s - loss: 22270917780.0262 - acc: 0.0000e+00 - val_loss: 23633405290.8147 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "0s - loss: 23102183639.9138 - acc: 0.0000e+00 - val_loss: 23972454284.8533 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "0s - loss: 22678851675.4419 - acc: 0.0000e+00 - val_loss: 23788994799.4546 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "0s - loss: 22057090838.0144 - acc: 0.0000e+00 - val_loss: 23123165594.9900 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "0s - loss: 22689140158.3121 - acc: 0.0000e+00 - val_loss: 23106261295.2670 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "0s - loss: 21209877255.4622 - acc: 0.0000e+00 - val_loss: 23667046516.5683 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "0s - loss: 22308646158.1292 - acc: 0.0000e+00 - val_loss: 23165325026.7395 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "0s - loss: 21844624647.6314 - acc: 0.0000e+00 - val_loss: 23052079073.5153 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "0s - loss: 22370081433.2040 - acc: 0.0000e+00 - val_loss: 23497117488.7675 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "0s - loss: 22556549455.2079 - acc: 0.0000e+00 - val_loss: 22957008754.6334 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "0s - loss: 22318870831.7346 - acc: 0.0000e+00 - val_loss: 22890546340.1117 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "0s - loss: 21844946295.5817 - acc: 0.0000e+00 - val_loss: 23213976101.0396 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "0s - loss: 22173649566.0097 - acc: 0.0000e+00 - val_loss: 23717397670.4809 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "0s - loss: 21678215542.0250 - acc: 0.0000e+00 - val_loss: 23405838097.1772 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "0s - loss: 22478598304.8186 - acc: 0.0000e+00 - val_loss: 23208067698.5939 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "0s - loss: 21575058843.0484 - acc: 0.0000e+00 - val_loss: 23256929517.5592 - val_acc: 1.5425e-04\n",
      "Epoch 148/500\n",
      "0s - loss: 22977922555.2959 - acc: 0.0000e+00 - val_loss: 23903548105.3093 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "0s - loss: 21186290131.1590 - acc: 0.0000e+00 - val_loss: 23207781660.4708 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "0s - loss: 21779483514.0522 - acc: 0.0000e+00 - val_loss: 23069384591.2226 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "0s - loss: 22440527647.1518 - acc: 0.0000e+00 - val_loss: 22788700160.7898 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "0s - loss: 22030326975.8858 - acc: 0.0000e+00 - val_loss: 23146866931.2454 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "0s - loss: 21694948690.2198 - acc: 0.0000e+00 - val_loss: 23496349269.5308 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "0s - loss: 21669427237.4973 - acc: 0.0000e+00 - val_loss: 22698492221.7985 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "0s - loss: 21383056227.6486 - acc: 0.0000e+00 - val_loss: 22932525835.1751 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "0s - loss: 21150602936.0682 - acc: 0.0000e+00 - val_loss: 23026695509.8072 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "0s - loss: 21786587058.5688 - acc: 0.0000e+00 - val_loss: 22758398611.4478 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "0s - loss: 20988036544.4103 - acc: 0.0000e+00 - val_loss: 22821785726.6772 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "0s - loss: 21271630652.5269 - acc: 0.0000e+00 - val_loss: 22842151686.2786 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "0s - loss: 21281729889.1781 - acc: 0.0000e+00 - val_loss: 23039509208.4726 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "0s - loss: 21714930805.8389 - acc: 0.0000e+00 - val_loss: 22940945950.8795 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "0s - loss: 20788213483.9823 - acc: 0.0000e+00 - val_loss: 23124914166.0491 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "0s - loss: 21317012467.1399 - acc: 0.0000e+00 - val_loss: 23003206253.6974 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "0s - loss: 21952235052.5703 - acc: 0.0000e+00 - val_loss: 23444956596.4202 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "0s - loss: 21398209692.8929 - acc: 0.0000e+00 - val_loss: 22791594358.6611 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "0s - loss: 21327739234.1257 - acc: 0.0000e+00 - val_loss: 22988787267.3663 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "0s - loss: 20870473889.6308 - acc: 0.0000e+00 - val_loss: 23154874275.1245 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "0s - loss: 20751759642.2447 - acc: 0.0000e+00 - val_loss: 22648808737.5252 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "0s - loss: 21006343254.9747 - acc: 0.0000e+00 - val_loss: 23262413980.6880 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "0s - loss: 21980386737.5197 - acc: 0.0000e+00 - val_loss: 22541432255.7927 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "0s - loss: 21993606271.3147 - acc: 0.0000e+00 - val_loss: 22894679388.5991 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "0s - loss: 22146594585.4663 - acc: 0.0000e+00 - val_loss: 22704550384.7577 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "0s - loss: 21886341746.8946 - acc: 0.0000e+00 - val_loss: 22609663924.9730 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "0s - loss: 21017971858.4017 - acc: 0.0000e+00 - val_loss: 22695444371.0134 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "0s - loss: 21811944641.9840 - acc: 0.0000e+00 - val_loss: 22645425875.5761 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "0s - loss: 20592384996.5877 - acc: 0.0000e+00 - val_loss: 22789109310.7857 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "0s - loss: 20568388785.5367 - acc: 0.0000e+00 - val_loss: 23028164943.0153 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "0s - loss: 21636803330.5889 - acc: 0.0000e+00 - val_loss: 23040824929.0612 - val_acc: 1.5425e-04\n",
      "Epoch 179/500\n",
      "0s - loss: 21710595076.8056 - acc: 6.6098e-05 - val_loss: 22760530953.3191 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "0s - loss: 20306208401.8264 - acc: 0.0000e+00 - val_loss: 22405345564.3128 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "0s - loss: 20674876525.7167 - acc: 0.0000e+00 - val_loss: 22552925580.9323 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "0s - loss: 20569674245.6517 - acc: 0.0000e+00 - val_loss: 22347683093.3629 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "0s - loss: 19702250536.5092 - acc: 0.0000e+00 - val_loss: 22450783298.1817 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "0s - loss: 20463959438.9329 - acc: 0.0000e+00 - val_loss: 22750520494.5365 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "0s - loss: 20827135116.9193 - acc: 6.6098e-05 - val_loss: 22230909537.3771 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "0s - loss: 20527663383.6727 - acc: 0.0000e+00 - val_loss: 22789742713.9386 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "0s - loss: 20898998288.2781 - acc: 0.0000e+00 - val_loss: 22594395152.2690 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "0s - loss: 20813497456.4241 - acc: 1.3220e-04 - val_loss: 22287335473.2809 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "0s - loss: 20517431854.1270 - acc: 0.0000e+00 - val_loss: 22393017800.3221 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "0s - loss: 19597283646.5913 - acc: 0.0000e+00 - val_loss: 22501986765.6924 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "0s - loss: 20517602982.5718 - acc: 0.0000e+00 - val_loss: 22410011895.1942 - val_acc: 1.5425e-04\n",
      "Epoch 192/500\n",
      "0s - loss: 21403449012.4132 - acc: 0.0000e+00 - val_loss: 22396985261.7072 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "0s - loss: 20100325430.1477 - acc: 0.0000e+00 - val_loss: 22342385305.2920 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "0s - loss: 20294413774.0826 - acc: 0.0000e+00 - val_loss: 22377874483.9661 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "0s - loss: 20868736507.0252 - acc: 0.0000e+00 - val_loss: 22306460253.2704 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "0s - loss: 20039356672.6599 - acc: 0.0000e+00 - val_loss: 22560403350.1725 - val_acc: 1.5425e-04\n",
      "Epoch 197/500\n",
      "0s - loss: 20207485760.5542 - acc: 0.0000e+00 - val_loss: 22653271157.3580 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "0s - loss: 20898330299.9262 - acc: 0.0000e+00 - val_loss: 22463876034.8727 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "0s - loss: 20795657033.3193 - acc: 0.0000e+00 - val_loss: 22125490365.6998 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "0s - loss: 21413984631.9202 - acc: 6.6098e-05 - val_loss: 21927575847.3694 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "0s - loss: 19857519096.0471 - acc: 0.0000e+00 - val_loss: 22334656690.3273 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "0s - loss: 20668332744.3125 - acc: 0.0000e+00 - val_loss: 22177181734.0663 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "0s - loss: 20127439113.9327 - acc: 0.0000e+00 - val_loss: 22020279013.8985 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "0s - loss: 20161489958.3095 - acc: 0.0000e+00 - val_loss: 22164033883.8093 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "0s - loss: 20440751547.1986 - acc: 0.0000e+00 - val_loss: 22342283170.0188 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "0s - loss: 20291829168.8767 - acc: 0.0000e+00 - val_loss: 22230070234.2496 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "0s - loss: 20198527263.4902 - acc: 0.0000e+00 - val_loss: 21955266834.6778 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "0s - loss: 20132065580.6549 - acc: 0.0000e+00 - val_loss: 22554773990.8067 - val_acc: 1.5425e-04\n",
      "Epoch 209/500\n",
      "0s - loss: 19816364201.3468 - acc: 0.0000e+00 - val_loss: 22324796606.1737 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "0s - loss: 20403906841.9740 - acc: 0.0000e+00 - val_loss: 22369155079.5817 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "0s - loss: 21210918649.1808 - acc: 0.0000e+00 - val_loss: 22090683272.2727 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "0s - loss: 19673159563.0410 - acc: 0.0000e+00 - val_loss: 22321942868.7015 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "0s - loss: 20622848708.5222 - acc: 0.0000e+00 - val_loss: 22189667685.2864 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "0s - loss: 20228972662.9895 - acc: 0.0000e+00 - val_loss: 22408592938.5679 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "0s - loss: 19941722958.8018 - acc: 0.0000e+00 - val_loss: 22061918274.1817 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "0s - loss: 20452584185.1808 - acc: 0.0000e+00 - val_loss: 22281675316.2030 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "0s - loss: 20062948566.8647 - acc: 0.0000e+00 - val_loss: 22252396649.3537 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "0s - loss: 20137607580.0637 - acc: 0.0000e+00 - val_loss: 22526706693.0545 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "0s - loss: 19507759101.6987 - acc: 0.0000e+00 - val_loss: 22482774372.0228 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "0s - loss: 20693152429.3741 - acc: 0.0000e+00 - val_loss: 21951494191.8593 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "0s - loss: 20050740612.9833 - acc: 0.0000e+00 - val_loss: 22692468825.2426 - val_acc: 1.5425e-04\n",
      "Epoch 222/500\n",
      "0s - loss: 20215349198.1842 - acc: 0.0000e+00 - val_loss: 22466520251.3306 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "0s - loss: 20677573966.1588 - acc: 0.0000e+00 - val_loss: 22562329300.9977 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "0s - loss: 20353395550.3015 - acc: 0.0000e+00 - val_loss: 22517001470.9338 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "0s - loss: 20104698432.8080 - acc: 0.0000e+00 - val_loss: 22105139085.3272 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "0s - loss: 20420822554.0247 - acc: 0.0000e+00 - val_loss: 21802910502.5007 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "0s - loss: 20149835276.7585 - acc: 0.0000e+00 - val_loss: 22090257656.9317 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "0s - loss: 19995386238.9594 - acc: 0.0000e+00 - val_loss: 22503007987.0085 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "0s - loss: 19856338666.4932 - acc: 0.0000e+00 - val_loss: 22437893794.1373 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "0s - loss: 20030527034.7841 - acc: 0.0000e+00 - val_loss: 22501818519.0017 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "0s - loss: 19410773084.5248 - acc: 0.0000e+00 - val_loss: 22257619428.1215 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "0s - loss: 20456609319.8324 - acc: 0.0000e+00 - val_loss: 22821749156.1512 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "0s - loss: 19989513852.3027 - acc: 0.0000e+00 - val_loss: 22110011256.0037 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "0s - loss: 20479838232.1634 - acc: 0.0000e+00 - val_loss: 22382755541.7874 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "0s - loss: 19773872123.2621 - acc: 0.0000e+00 - val_loss: 22236283299.5194 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "0s - loss: 19508127840.5182 - acc: 0.0000e+00 - val_loss: 22134089383.3497 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "0s - loss: 19446823212.9256 - acc: 0.0000e+00 - val_loss: 22039264984.1567 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "0s - loss: 19875932507.8987 - acc: 0.0000e+00 - val_loss: 21961681209.3759 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "0s - loss: 19866152118.8160 - acc: 0.0000e+00 - val_loss: 22716577356.3696 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "0s - loss: 20984759834.8369 - acc: 0.0000e+00 - val_loss: 22492413349.5727 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "0s - loss: 19503553886.4707 - acc: 6.6098e-05 - val_loss: 22518380394.2619 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "0s - loss: 19681600901.4571 - acc: 0.0000e+00 - val_loss: 22262416690.2681 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "0s - loss: 20228804285.2799 - acc: 0.0000e+00 - val_loss: 22236446725.0545 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "0s - loss: 19368182469.0637 - acc: 0.0000e+00 - val_loss: 22463151125.9553 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "0s - loss: 20493975226.3018 - acc: 0.0000e+00 - val_loss: 22023182430.4550 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "0s - loss: 20963670612.0304 - acc: 0.0000e+00 - val_loss: 22062792454.1206 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "0s - loss: 19647729644.3715 - acc: 0.0000e+00 - val_loss: 22135948543.5656 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "0s - loss: 20875607264.8482 - acc: 0.0000e+00 - val_loss: 22059003737.8349 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "0s - loss: 20513550003.0596 - acc: 0.0000e+00 - val_loss: 22001306673.4388 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "0s - loss: 19140785450.7597 - acc: 0.0000e+00 - val_loss: 21756760074.2669 - val_acc: 1.5425e-04\n",
      "Epoch 251/500\n",
      "0s - loss: 19386931030.0440 - acc: 0.0000e+00 - val_loss: 22324690748.4560 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "0s - loss: 20616224222.3269 - acc: 0.0000e+00 - val_loss: 22445582368.5380 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "0s - loss: 19670905946.0882 - acc: 0.0000e+00 - val_loss: 21924155366.2539 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "0s - loss: 19056017671.6991 - acc: 0.0000e+00 - val_loss: 21695347536.1999 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "0s - loss: 19590804013.0441 - acc: 6.6098e-05 - val_loss: 21901835817.4623 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "0s - loss: 18393534157.4904 - acc: 0.0000e+00 - val_loss: 21533907375.2078 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "0s - loss: 18734401076.0156 - acc: 0.0000e+00 - val_loss: 21720916832.1530 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "0s - loss: 19974432003.2996 - acc: 0.0000e+00 - val_loss: 22238860468.6966 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "0s - loss: 19770898596.2705 - acc: 0.0000e+00 - val_loss: 21696588815.0054 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "0s - loss: 20059238304.5647 - acc: 0.0000e+00 - val_loss: 21741851800.5812 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "0s - loss: 19425417976.2332 - acc: 6.6098e-05 - val_loss: 21645302415.4990 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "0s - loss: 18978922286.7193 - acc: 0.0000e+00 - val_loss: 21633475718.4168 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "0s - loss: 19766008518.7896 - acc: 0.0000e+00 - val_loss: 21925971779.4058 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "0s - loss: 19442626540.3715 - acc: 0.0000e+00 - val_loss: 21843894175.0177 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "0s - loss: 19302384535.1566 - acc: 0.0000e+00 - val_loss: 22043295385.1340 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "0s - loss: 20191170073.8217 - acc: 0.0000e+00 - val_loss: 21809789985.0119 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "0s - loss: 19258030583.0318 - acc: 6.6098e-05 - val_loss: 21954549847.9790 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "0s - loss: 18868181533.7474 - acc: 0.0000e+00 - val_loss: 21580069408.7749 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "0s - loss: 19547065396.9293 - acc: 0.0000e+00 - val_loss: 21780938004.0993 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "0s - loss: 19811498314.4361 - acc: 0.0000e+00 - val_loss: 22335437784.3542 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "0s - loss: 20024202068.5550 - acc: 0.0000e+00 - val_loss: 21499916372.0302 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "0s - loss: 19747255609.1766 - acc: 0.0000e+00 - val_loss: 22574249740.7546 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "0s - loss: 18991564125.3201 - acc: 0.0000e+00 - val_loss: 22633114772.6324 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "0s - loss: 19379021002.6138 - acc: 0.0000e+00 - val_loss: 21771957036.3449 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "0s - loss: 18748655518.6019 - acc: 0.0000e+00 - val_loss: 21613465696.1925 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "0s - loss: 19445256975.9228 - acc: 0.0000e+00 - val_loss: 21819809936.0518 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "0s - loss: 17845829998.8843 - acc: 0.0000e+00 - val_loss: 21610369359.9630 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "0s - loss: 19749279521.9946 - acc: 0.0000e+00 - val_loss: 21664766947.7267 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "0s - loss: 19542925663.9598 - acc: 0.0000e+00 - val_loss: 21603319124.7015 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "0s - loss: 19299590231.2454 - acc: 0.0000e+00 - val_loss: 22279048674.2261 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "0s - loss: 19443643615.6975 - acc: 0.0000e+00 - val_loss: 21966369846.1774 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "0s - loss: 19595456258.7920 - acc: 0.0000e+00 - val_loss: 21380118425.6474 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "0s - loss: 19590646276.1626 - acc: 6.6098e-05 - val_loss: 21848028467.6897 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "0s - loss: 19215008007.3607 - acc: 0.0000e+00 - val_loss: 21640865477.5184 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "0s - loss: 18411523952.8471 - acc: 0.0000e+00 - val_loss: 21786562733.9047 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "0s - loss: 19007597084.1229 - acc: 0.0000e+00 - val_loss: 21853365214.6722 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "0s - loss: 19464218817.0364 - acc: 0.0000e+00 - val_loss: 21691086779.6070 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "0s - loss: 19331350189.5771 - acc: 0.0000e+00 - val_loss: 21580219547.1084 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "0s - loss: 19465135466.1802 - acc: 0.0000e+00 - val_loss: 21844901250.3495 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "0s - loss: 19771123542.6193 - acc: 0.0000e+00 - val_loss: 22011774167.1300 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "0s - loss: 20042083913.5393 - acc: 6.6098e-05 - val_loss: 21901401151.4965 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "0s - loss: 19238337386.3494 - acc: 0.0000e+00 - val_loss: 21812752250.5309 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "0s - loss: 18810224056.6943 - acc: 0.0000e+00 - val_loss: 21939055561.3488 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "0s - loss: 18978548896.5478 - acc: 0.0000e+00 - val_loss: 21764402503.1177 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "0s - loss: 18766150190.8377 - acc: 0.0000e+00 - val_loss: 21860519564.3400 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "0s - loss: 18774533937.6297 - acc: 0.0000e+00 - val_loss: 21755409607.6508 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "0s - loss: 19445761118.8938 - acc: 0.0000e+00 - val_loss: 21889270240.4887 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "0s - loss: 19282966027.0664 - acc: 0.0000e+00 - val_loss: 21789825805.7023 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "0s - loss: 18960316175.1783 - acc: 0.0000e+00 - val_loss: 21575490887.5915 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "0s - loss: 19717277440.2877 - acc: 0.0000e+00 - val_loss: 21691013067.8760 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "0s - loss: 19121816111.0746 - acc: 0.0000e+00 - val_loss: 21614557932.0586 - val_acc: 1.5425e-04\n",
      "Epoch 302/500\n",
      "0s - loss: 19260298668.2403 - acc: 0.0000e+00 - val_loss: 21751433138.4458 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "0s - loss: 18200539761.8793 - acc: 0.0000e+00 - val_loss: 21616998554.4766 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "0s - loss: 19181282358.8922 - acc: 0.0000e+00 - val_loss: 21495013967.3707 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "0s - loss: 18633185335.9075 - acc: 0.0000e+00 - val_loss: 21776035030.9721 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "0s - loss: 19864446454.0165 - acc: 0.0000e+00 - val_loss: 21607303240.3418 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "0s - loss: 18550898578.0802 - acc: 0.0000e+00 - val_loss: 21428089686.9918 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "0s - loss: 19170613138.4864 - acc: 0.0000e+00 - val_loss: 21888213438.6870 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "0s - loss: 18686435111.4093 - acc: 0.0000e+00 - val_loss: 21687701830.8018 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "0s - loss: 20158552539.0781 - acc: 0.0000e+00 - val_loss: 21401502774.1774 - val_acc: 1.5425e-04\n",
      "Epoch 311/500\n",
      "0s - loss: 19069970571.7010 - acc: 0.0000e+00 - val_loss: 21317172528.8465 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "0s - loss: 19950737525.1620 - acc: 0.0000e+00 - val_loss: 21315572945.7597 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "0s - loss: 19410744529.5853 - acc: 0.0000e+00 - val_loss: 21782146343.3694 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "0s - loss: 19275572700.7025 - acc: 0.0000e+00 - val_loss: 21872572899.8056 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "0s - loss: 19720726495.6468 - acc: 0.0000e+00 - val_loss: 21885600424.7712 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "0s - loss: 18540071892.4788 - acc: 0.0000e+00 - val_loss: 22212574753.0909 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "0s - loss: 19752617393.8582 - acc: 0.0000e+00 - val_loss: 22092038257.5672 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "0s - loss: 19415665007.5273 - acc: 0.0000e+00 - val_loss: 21889096875.5354 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "0s - loss: 19303630438.7113 - acc: 0.0000e+00 - val_loss: 21533260719.1288 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "0s - loss: 19186709341.6247 - acc: 0.0000e+00 - val_loss: 21489514890.4051 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "0s - loss: 19048916918.0208 - acc: 6.6098e-05 - val_loss: 22522448963.1294 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "0s - loss: 19220491612.3725 - acc: 0.0000e+00 - val_loss: 21564447659.8118 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "0s - loss: 19383879260.5248 - acc: 0.0000e+00 - val_loss: 22016679721.5018 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "0s - loss: 19338225339.0463 - acc: 0.0000e+00 - val_loss: 22201928421.8985 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "0s - loss: 19119967292.5100 - acc: 0.0000e+00 - val_loss: 21701750172.2536 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "0s - loss: 18739465226.0512 - acc: 0.0000e+00 - val_loss: 21486673982.5488 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "0s - loss: 18437607629.6934 - acc: 0.0000e+00 - val_loss: 21369014061.1347 - val_acc: 1.5425e-04\n",
      "Epoch 328/500\n",
      "0s - loss: 19304396844.6718 - acc: 0.0000e+00 - val_loss: 21887804843.1010 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "0s - loss: 18549894178.0453 - acc: 0.0000e+00 - val_loss: 21778271421.3839 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "0s - loss: 19062110744.6710 - acc: 0.0000e+00 - val_loss: 21524453952.2073 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "0s - loss: 19024941987.0014 - acc: 0.0000e+00 - val_loss: 21541879207.7840 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "0s - loss: 18824047051.5106 - acc: 0.0000e+00 - val_loss: 21564036052.5633 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "0s - loss: 18830761547.9083 - acc: 0.0000e+00 - val_loss: 21732898916.2992 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "0s - loss: 19018128483.4286 - acc: 0.0000e+00 - val_loss: 21667792119.3521 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "0s - loss: 18961464676.8331 - acc: 0.0000e+00 - val_loss: 21689138120.8749 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "0s - loss: 18957939634.5012 - acc: 0.0000e+00 - val_loss: 21596686293.0372 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "0s - loss: 19175804606.3629 - acc: 0.0000e+00 - val_loss: 21582955782.5155 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "0s - loss: 18679552970.3261 - acc: 0.0000e+00 - val_loss: 21735768406.9128 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "0s - loss: 18680558384.1407 - acc: 0.0000e+00 - val_loss: 21760342369.1797 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "0s - loss: 18852094117.5565 - acc: 0.0000e+00 - val_loss: 21723053891.4058 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "0s - loss: 18989123695.8149 - acc: 0.0000e+00 - val_loss: 21585103346.8110 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "0s - loss: 18437329919.7969 - acc: 0.0000e+00 - val_loss: 21689954886.3674 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "0s - loss: 19240678470.2566 - acc: 0.0000e+00 - val_loss: 21302814762.3310 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "0s - loss: 18303232231.0075 - acc: 0.0000e+00 - val_loss: 21808241117.1717 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "0s - loss: 19141584546.0707 - acc: 0.0000e+00 - val_loss: 21919013280.2024 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "0s - loss: 18903907557.5184 - acc: 0.0000e+00 - val_loss: 22063169372.5201 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "0s - loss: 18369201073.6889 - acc: 0.0000e+00 - val_loss: 21819171171.8649 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "0s - loss: 19143426136.1930 - acc: 6.6098e-05 - val_loss: 21441774412.0932 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "0s - loss: 18980524421.9985 - acc: 0.0000e+00 - val_loss: 21712120484.1907 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "0s - loss: 18261101224.9069 - acc: 0.0000e+00 - val_loss: 21340259910.0515 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "0s - loss: 18931520668.2837 - acc: 0.0000e+00 - val_loss: 21639470959.4743 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "0s - loss: 19186714919.2740 - acc: 0.0000e+00 - val_loss: 21458256148.8891 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "0s - loss: 18878571521.3537 - acc: 0.0000e+00 - val_loss: 21673280686.3785 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "0s - loss: 17908335067.1457 - acc: 0.0000e+00 - val_loss: 21507791236.7188 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "0s - loss: 18813970056.8921 - acc: 0.0000e+00 - val_loss: 21370486079.6940 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "0s - loss: 18442951081.1268 - acc: 0.0000e+00 - val_loss: 21600363585.5499 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "0s - loss: 18697586697.8143 - acc: 0.0000e+00 - val_loss: 21553769135.7211 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "0s - loss: 19035181974.0736 - acc: 0.0000e+00 - val_loss: 21748015176.0259 - val_acc: 1.5425e-04\n",
      "Epoch 359/500\n",
      "0s - loss: 18574423782.6352 - acc: 0.0000e+00 - val_loss: 21541061201.5820 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "0s - loss: 18045228586.1337 - acc: 0.0000e+00 - val_loss: 21443073852.6139 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "0s - loss: 19005640014.1926 - acc: 0.0000e+00 - val_loss: 21342562819.7119 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "0s - loss: 17861276991.4035 - acc: 0.0000e+00 - val_loss: 21380762734.2502 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "0s - loss: 18532746299.6640 - acc: 0.0000e+00 - val_loss: 21243625902.1021 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "0s - loss: 19043997217.6731 - acc: 0.0000e+00 - val_loss: 21768761870.4526 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "0s - loss: 18843530320.0709 - acc: 6.6098e-05 - val_loss: 21821041519.7902 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "0s - loss: 18622323520.3850 - acc: 0.0000e+00 - val_loss: 21621854938.9998 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "0s - loss: 18473257126.5041 - acc: 0.0000e+00 - val_loss: 21411883986.8259 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "0s - loss: 18270671583.5960 - acc: 0.0000e+00 - val_loss: 22120623844.6349 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "0s - loss: 19157885891.3546 - acc: 0.0000e+00 - val_loss: 21484088606.0503 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "0s - loss: 17954416885.5597 - acc: 0.0000e+00 - val_loss: 21445208161.4561 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "0s - loss: 18736022147.3419 - acc: 0.0000e+00 - val_loss: 21585285751.4904 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "0s - loss: 18103667498.9289 - acc: 0.0000e+00 - val_loss: 21396344878.1219 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "0s - loss: 18999947364.9854 - acc: 0.0000e+00 - val_loss: 21070362268.6090 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "0s - loss: 19938903984.1322 - acc: 0.0000e+00 - val_loss: 21480870029.8405 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "0s - loss: 17974870094.1080 - acc: 0.0000e+00 - val_loss: 21651398156.8731 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "0s - loss: 18350080309.9277 - acc: 0.0000e+00 - val_loss: 21495205392.6639 - val_acc: 0.0000e+00\n",
      "Epoch 377/500\n",
      "0s - loss: 18752313687.1608 - acc: 0.0000e+00 - val_loss: 21734682504.2727 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "0s - loss: 18541484604.4762 - acc: 0.0000e+00 - val_loss: 21496160333.3963 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "0s - loss: 17738640325.3175 - acc: 0.0000e+00 - val_loss: 21304879108.7385 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "0s - loss: 18289102321.9554 - acc: 0.0000e+00 - val_loss: 21273774544.6935 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "0s - loss: 18601292860.2393 - acc: 0.0000e+00 - val_loss: 21503311024.4319 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "0s - loss: 19484165994.4171 - acc: 0.0000e+00 - val_loss: 21526783301.2223 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "0s - loss: 18469878089.3532 - acc: 0.0000e+00 - val_loss: 21445587666.3125 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "0s - loss: 18616484913.5451 - acc: 0.0000e+00 - val_loss: 21472216678.4316 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "0s - loss: 18613340654.4359 - acc: 6.6098e-05 - val_loss: 21396778977.9892 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "0s - loss: 17958048577.8063 - acc: 0.0000e+00 - val_loss: 21479110524.2684 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "0s - loss: 18657274793.3976 - acc: 0.0000e+00 - val_loss: 21526849639.9321 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "0s - loss: 18898756957.1847 - acc: 0.0000e+00 - val_loss: 21519414083.8797 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "0s - loss: 18360968539.5603 - acc: 0.0000e+00 - val_loss: 21464374508.1376 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "0s - loss: 18540387003.1817 - acc: 0.0000e+00 - val_loss: 21151499781.6073 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "0s - loss: 18617180854.0377 - acc: 0.0000e+00 - val_loss: 22061263637.4419 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "0s - loss: 19086323117.1879 - acc: 0.0000e+00 - val_loss: 21546251249.9423 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "0s - loss: 17776108724.2440 - acc: 0.0000e+00 - val_loss: 21330969189.1680 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "0s - loss: 18295610030.5924 - acc: 6.6098e-05 - val_loss: 21478727600.2345 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "0s - loss: 18340283071.5135 - acc: 0.0000e+00 - val_loss: 22149215280.0173 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "0s - loss: 18657194513.4965 - acc: 0.0000e+00 - val_loss: 21848831176.4405 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "0s - loss: 18704719351.6410 - acc: 0.0000e+00 - val_loss: 21870064650.1089 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "0s - loss: 18908142952.0143 - acc: 0.0000e+00 - val_loss: 22016064811.9500 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "0s - loss: 18412738446.8991 - acc: 0.0000e+00 - val_loss: 21610558938.6445 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "0s - loss: 18760660748.1325 - acc: 6.6098e-05 - val_loss: 21759502761.9954 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "0s - loss: 19298354573.1731 - acc: 0.0000e+00 - val_loss: 21624657664.5923 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "0s - loss: 19385412857.6207 - acc: 0.0000e+00 - val_loss: 21078709747.6008 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "0s - loss: 18374023191.0128 - acc: 6.6098e-05 - val_loss: 21234071590.8561 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "0s - loss: 18180102788.8310 - acc: 0.0000e+00 - val_loss: 21513159780.1413 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "0s - loss: 18640079847.5659 - acc: 6.6098e-05 - val_loss: 21778210918.3526 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "0s - loss: 18044838367.2068 - acc: 0.0000e+00 - val_loss: 21281041214.9832 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "0s - loss: 17895658058.3854 - acc: 6.6098e-05 - val_loss: 21187590058.5482 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "0s - loss: 18642366018.6355 - acc: 0.0000e+00 - val_loss: 21164650537.3833 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "0s - loss: 17790663423.1370 - acc: 0.0000e+00 - val_loss: 21208392805.8788 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "0s - loss: 18678310959.3792 - acc: 0.0000e+00 - val_loss: 21434162181.3704 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "0s - loss: 17863373411.4625 - acc: 6.6098e-05 - val_loss: 21457348651.5946 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "0s - loss: 18522987347.1336 - acc: 0.0000e+00 - val_loss: 21634058840.8478 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "0s - loss: 18163260018.8946 - acc: 0.0000e+00 - val_loss: 21955028149.4863 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "0s - loss: 18192720760.4955 - acc: 0.0000e+00 - val_loss: 21577803719.9272 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "0s - loss: 18117655370.9099 - acc: 0.0000e+00 - val_loss: 22070186413.9442 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "0s - loss: 17977388102.3920 - acc: 0.0000e+00 - val_loss: 21504562143.6199 - val_acc: 1.5425e-04\n",
      "Epoch 417/500\n",
      "0s - loss: 18222152672.9328 - acc: 0.0000e+00 - val_loss: 21208756098.7444 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "0s - loss: 18474777267.8718 - acc: 0.0000e+00 - val_loss: 21445806523.3700 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "0s - loss: 18731292266.2309 - acc: 6.6098e-05 - val_loss: 21721821393.4438 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "0s - loss: 18323128222.8049 - acc: 0.0000e+00 - val_loss: 21646065473.6684 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "0s - loss: 17745512656.8915 - acc: 0.0000e+00 - val_loss: 21731112231.5274 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "0s - loss: 18380507051.9358 - acc: 0.0000e+00 - val_loss: 21551043840.1974 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "0s - loss: 18304907806.3565 - acc: 6.6098e-05 - val_loss: 21798711026.6926 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "0s - loss: 18474930830.3745 - acc: 0.0000e+00 - val_loss: 22303730537.4722 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "0s - loss: 18205150252.1980 - acc: 0.0000e+00 - val_loss: 21777800861.5567 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "0s - loss: 17324639070.7753 - acc: 0.0000e+00 - val_loss: 21464869891.9488 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "0s - loss: 18315680846.5818 - acc: 0.0000e+00 - val_loss: 21505617206.3748 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "0s - loss: 18448854844.3916 - acc: 0.0000e+00 - val_loss: 21686740580.6941 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "0s - loss: 18808276222.8324 - acc: 6.6098e-05 - val_loss: 21236948097.6782 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "0s - loss: 18125247476.8320 - acc: 0.0000e+00 - val_loss: 21193273727.1905 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "0s - loss: 17951208609.9692 - acc: 0.0000e+00 - val_loss: 21435387382.9178 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "0s - loss: 18759729488.4600 - acc: 0.0000e+00 - val_loss: 21968834497.7671 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "0s - loss: 18007814465.5694 - acc: 0.0000e+00 - val_loss: 21500983199.0177 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "0s - loss: 18341138377.0401 - acc: 0.0000e+00 - val_loss: 21464089981.4530 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "0s - loss: 18795748639.3210 - acc: 0.0000e+00 - val_loss: 21509327162.0077 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "0s - loss: 18718333672.5304 - acc: 0.0000e+00 - val_loss: 21896703537.0440 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "0s - loss: 18387310714.4414 - acc: 0.0000e+00 - val_loss: 21527280621.2038 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "0s - loss: 18164898412.4645 - acc: 6.6098e-05 - val_loss: 21951592193.3821 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "0s - loss: 19258953221.7193 - acc: 6.6098e-05 - val_loss: 21865017139.2948 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "0s - loss: 18109562349.5898 - acc: 0.0000e+00 - val_loss: 21343864493.9837 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "0s - loss: 17929142915.5788 - acc: 0.0000e+00 - val_loss: 21414090493.5912 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "0s - loss: 18322106476.0923 - acc: 0.0000e+00 - val_loss: 21735307413.7381 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "0s - loss: 18722343764.1489 - acc: 6.6098e-05 - val_loss: 21874776773.6764 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "0s - loss: 17843825526.8034 - acc: 0.0000e+00 - val_loss: 21577091235.6378 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "0s - loss: 17377702613.4433 - acc: 0.0000e+00 - val_loss: 21269030462.1539 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "0s - loss: 18664670743.1820 - acc: 0.0000e+00 - val_loss: 21363721505.9991 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "0s - loss: 17689314795.3224 - acc: 0.0000e+00 - val_loss: 21690339489.7424 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "0s - loss: 18102812999.8641 - acc: 0.0000e+00 - val_loss: 21471627472.3381 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "0s - loss: 17923600574.5321 - acc: 6.6098e-05 - val_loss: 21580761054.8302 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "0s - loss: 17698645689.4896 - acc: 0.0000e+00 - val_loss: 21439208195.4354 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "0s - loss: 17874554776.3072 - acc: 0.0000e+00 - val_loss: 21775301836.8632 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "0s - loss: 17609931254.8964 - acc: 0.0000e+00 - val_loss: 21432304029.8331 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "0s - loss: 17840835275.2229 - acc: 0.0000e+00 - val_loss: 21992256376.6355 - val_acc: 1.5425e-04\n",
      "Epoch 454/500\n",
      "0s - loss: 18634044310.9874 - acc: 0.0000e+00 - val_loss: 22113332834.1669 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "0s - loss: 18952425207.1502 - acc: 0.0000e+00 - val_loss: 21442579342.1169 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "0s - loss: 17818696865.0216 - acc: 0.0000e+00 - val_loss: 21600103388.7768 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "0s - loss: 18345976728.9841 - acc: 0.0000e+00 - val_loss: 21549002824.3418 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "0s - loss: 18768596809.2516 - acc: 0.0000e+00 - val_loss: 21304285489.4783 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "0s - loss: 18080357334.5770 - acc: 0.0000e+00 - val_loss: 21378634573.3568 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "0s - loss: 18283129178.0036 - acc: 0.0000e+00 - val_loss: 21356879211.7625 - val_acc: 1.5425e-04\n",
      "Epoch 461/500\n",
      "0s - loss: 17520210807.6833 - acc: 0.0000e+00 - val_loss: 21260709870.6253 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "0s - loss: 17942657217.1041 - acc: 6.6098e-05 - val_loss: 21339693937.0538 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "0s - loss: 18181777267.6222 - acc: 0.0000e+00 - val_loss: 21566190635.4367 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "0s - loss: 18173342353.7587 - acc: 0.0000e+00 - val_loss: 21515837617.2217 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "0s - loss: 18016122558.6336 - acc: 0.0000e+00 - val_loss: 21364807830.8437 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "0s - loss: 18156749280.9666 - acc: 0.0000e+00 - val_loss: 21172508688.1111 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "0s - loss: 18243587995.5561 - acc: 0.0000e+00 - val_loss: 21515429570.2015 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "0s - loss: 17795545966.6812 - acc: 0.0000e+00 - val_loss: 21244699477.5703 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "0s - loss: 17944213939.0765 - acc: 0.0000e+00 - val_loss: 21299491027.9710 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "0s - loss: 18462339918.8695 - acc: 0.0000e+00 - val_loss: 21790211907.7217 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "0s - loss: 18477767065.3225 - acc: 0.0000e+00 - val_loss: 21388678016.2172 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "0s - loss: 18063601273.3923 - acc: 0.0000e+00 - val_loss: 21560521133.9442 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "0s - loss: 18638054157.0124 - acc: 0.0000e+00 - val_loss: 21357878241.1994 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "0s - loss: 18257508814.1842 - acc: 6.6098e-05 - val_loss: 21346734782.4106 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "0s - loss: 18178978872.6520 - acc: 6.6098e-05 - val_loss: 21317664653.6431 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "0s - loss: 18014021788.6898 - acc: 0.0000e+00 - val_loss: 21310812748.8434 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "0s - loss: 17795401000.1877 - acc: 6.6098e-05 - val_loss: 21365226620.3079 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "0s - loss: 17639331092.4915 - acc: 0.0000e+00 - val_loss: 21402294096.8317 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "0s - loss: 18129521736.6256 - acc: 6.6098e-05 - val_loss: 21174933872.6590 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "0s - loss: 18157386511.5167 - acc: 0.0000e+00 - val_loss: 21492653654.0046 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "0s - loss: 17884239292.2139 - acc: 6.6098e-05 - val_loss: 21374899144.8749 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "0s - loss: 17324510607.2713 - acc: 0.0000e+00 - val_loss: 21615192715.2343 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "0s - loss: 18323826447.1444 - acc: 0.0000e+00 - val_loss: 21444150842.0472 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "0s - loss: 18435910408.0037 - acc: 0.0000e+00 - val_loss: 21640185106.2039 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "0s - loss: 18461641574.4237 - acc: 6.6098e-05 - val_loss: 21524509587.1714 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "0s - loss: 18248647501.0420 - acc: 0.0000e+00 - val_loss: 22130412530.8900 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "0s - loss: 17715023597.7421 - acc: 0.0000e+00 - val_loss: 21400851428.6744 - val_acc: 1.5425e-04\n",
      "Epoch 488/500\n",
      "0s - loss: 18720843881.9941 - acc: 0.0000e+00 - val_loss: 21240971682.2557 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "0s - loss: 17848888205.1393 - acc: 0.0000e+00 - val_loss: 21227991558.8709 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "0s - loss: 18437693847.7996 - acc: 0.0000e+00 - val_loss: 21191276834.9468 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "0s - loss: 18864505388.6718 - acc: 0.0000e+00 - val_loss: 21422676603.4391 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "0s - loss: 17061480875.4281 - acc: 0.0000e+00 - val_loss: 21433863348.3807 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "0s - loss: 18214222646.1984 - acc: 0.0000e+00 - val_loss: 21518931866.1212 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "0s - loss: 17761191442.9855 - acc: 0.0000e+00 - val_loss: 21651191004.0265 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "0s - loss: 18576090126.5522 - acc: 0.0000e+00 - val_loss: 21501043461.6468 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "0s - loss: 18085635341.6892 - acc: 0.0000e+00 - val_loss: 21418159928.0333 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "0s - loss: 17897881678.8864 - acc: 0.0000e+00 - val_loss: 22347111662.9807 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "0s - loss: 17629485669.0869 - acc: 0.0000e+00 - val_loss: 21697246924.6263 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "0s - loss: 17650619341.1012 - acc: 0.0000e+00 - val_loss: 21760800320.5232 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "0s - loss: 17333019860.8003 - acc: 0.0000e+00 - val_loss: 21570089328.9749 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(arr_x_train, arr_y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2, # Change it to 2, if wished to observe execution\n",
    "    validation_data=(arr_x_valid, arr_y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bcea5d4-bc13-4f7f-8a72-036029842258",
    "_uuid": "da2984e773d6d777a4a3688861737619a5eac6b8"
   },
   "source": [
    "## Evaluate and report performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "655cc9e2-4c66-442e-b492-c779a81f45a3",
    "_uuid": "b0be62f94a064ff15436a0db15826267bd8b6506",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE:  69928.9177 , Train Loss:  14133538137.9\n",
      "Val MAE:  78698.3085 , Val Loss:  22450837718.8\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(arr_x_train, arr_y_train, verbose=0)\n",
    "valid_score = model.evaluate(arr_x_valid, arr_y_valid, verbose=0)\n",
    "\n",
    "print('Train MAE: ', round(train_score[1], 4), ', Train Loss: ', round(train_score[0], 4)) \n",
    "print('Val MAE: ', round(valid_score[1], 4), ', Val Loss: ', round(valid_score[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e165926-1bf7-4833-a034-3d5d90c5bb25",
    "_uuid": "80e67ebe59369a554151f0ff4a1008c9da685271"
   },
   "source": [
    "*This function allows plotting of the training history*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "46f992fc-36f3-4889-bdfa-2909f6b7164c",
    "_uuid": "004742724c0731a87996fe0e912f2fac882a89d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(h, xsize=6, ysize=10):\n",
    "    # Prepare plotting\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)\n",
    "    \n",
    "    # summarize history for MAE\n",
    "    plt.subplot(211)\n",
    "    plt.plot(h['mean_absolute_error'])\n",
    "    plt.plot(h['val_mean_absolute_error'])\n",
    "    plt.title('Training vs Validation MAE')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.subplot(212)\n",
    "    plt.plot(h['loss'])\n",
    "    plt.plot(h['val_loss'])\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot it all in IPython (non-interactive)\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "935ab404-a58c-47c3-84c1-52997731f51b",
    "_uuid": "02b5226b26bd537610da01d9beb3e38e65b1daca"
   },
   "source": [
    "*Now plot the training history, i.e. the Mean Absolute Error and Loss (Mean Squared Error), which were both defined at the time of model compilation. Note that the plot shows validation error as less than training error, which is quite deceptive. The reason for this is that training error is calculated for the entire epoch (and at its begining it was much worse than at the end), whereas the validation error is taken from the last batch (after the model improved). See the above evaluation statistics to confirm that the evaluation puts these errors in the correct order at the very end.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "50541547-c5f8-4159-98e5-d519e043ca9c",
    "_uuid": "eb351f894aee72be6230be8ff40f3538a76dcaa9",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAALJCAYAAAA6f2BxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISIiIhqlWIiIiIhGKRYiIiKi0Z+YSdwX7yw8PgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f072abe0198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history.history, xsize=8, ysize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before subtract::  1000000000.9536753\n",
      "0.9536752700805664\n"
     ]
    }
   ],
   "source": [
    "x=1e9\n",
    "count = 0\n",
    "while count < 1000001:\n",
    "    x += 0.000001\n",
    "    count += 1\n",
    "print('before subtract:: ', x)\n",
    "x = x - 1e9\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
